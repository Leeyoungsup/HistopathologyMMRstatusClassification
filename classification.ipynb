{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "import os\n",
    "from copy import copy\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import datasets, layers, models, losses, Model\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list=glob('../../data/CycleGAN360/*.jpg')\n",
    "img_slidename_list=copy(img_list)\n",
    "for i in range(len(img_list)):\n",
    "    img_slidename_list[i]=os.path.basename(img_list[i])[:9]\n",
    "label=pd.read_csv('../../data/P53&MMR.csv')\n",
    "img_index_list=[]\n",
    "for j in range(len(label['PathologyNumber'])):\n",
    "    img_index_list.append([i for i, ele in enumerate(img_slidename_list) if ele == label['PathologyNumber'][j]])\n",
    "label_list=copy(label['MMR status'].to_list())\n",
    "for i in range(len(label_list)):\n",
    "    if label_list[i]==\"Defect\":\n",
    "        label_list[i]=1\n",
    "    else:\n",
    "        label_list[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(img_index_list,label_list, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_x_train,list_x_test,list_y_train,list_y_test=[],[],[],[]\n",
    "for i in range(len(x_train)):\n",
    "    x_list=[]\n",
    "    if len(x_train[i])>100:                                  \n",
    "        for k in range(100):\n",
    "            a = random.randint(x_train[i][0],x_train[i][len(x_train[i])-1])       \n",
    "            while a in x_list :              # a가 이미 뽑은 리스트에 있을 때까지 다시 뽑자\n",
    "                a = random.randint(x_train[i][0],x_train[i][len(x_train[i])-1])\n",
    "            x_list.append(a) # 새로운 a 값을 리스트에 추가\n",
    "    else:\n",
    "        x_list=copy(x_train[i])\n",
    "    for j in x_list:\n",
    "        list_x_train.append(img_list[j])\n",
    "        list_y_train.append(y_train[i])\n",
    "        \n",
    "for i in range(len(x_test)):\n",
    "    x_list=[]\n",
    "    if len(x_test[i])>100:                                  \n",
    "        for k in range(100):\n",
    "            a = random.randint(x_test[i][0],x_test[i][len(x_test[i])-1])       \n",
    "            while a in x_list :              # a가 이미 뽑은 리스트에 있을 때까지 다시 뽑자\n",
    "                a = random.randint(x_test[i][0],x_test[i][len(x_test[i])-1])\n",
    "            x_list.append(a) # 새로운 a 값을 리스트에 추가\n",
    "    else:\n",
    "        x_list=copy(x_test[i])\n",
    "    for j in x_list:\n",
    "        list_x_test.append(img_list[j])\n",
    "        list_y_test.append(y_test[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=224\n",
    "x_train=np.zeros((len(list_x_train),img_size,img_size,3))\n",
    "x_test=np.zeros((len(list_x_test),img_size,img_size,3))\n",
    "y_train=np.zeros((len(list_y_train),1),dtype=np.float32)\n",
    "y_test=np.zeros((len(list_y_test),1),dtype=np.float32)\n",
    "\n",
    "for i in range(len(list_x_train)):\n",
    "    x_train[i]=Image.open(list_x_train[i])\n",
    "    y_train[i]=list_y_train[i]\n",
    "\n",
    "for i in range(len(list_x_test)):\n",
    "    x_test[i]=Image.open(list_x_test[i])\n",
    "    y_test[i]=list_y_test[i]\n",
    "    \n",
    "x_train=(x_train-255.0)/-255.0\n",
    "x_test=(x_test-255.0)/-255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 13:37:56.958996: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-12 13:37:57.489532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38196 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 13:38:19.863519: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-07-12 13:38:20.760721: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905/905 [==============================] - 52s 50ms/step - loss: 0.5162 - accuracy: 0.7906 - val_loss: 0.5421 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 2/300\n",
      "905/905 [==============================] - 42s 47ms/step - loss: 0.5142 - accuracy: 0.7906 - val_loss: 0.5413 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 3/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5139 - accuracy: 0.7906 - val_loss: 0.5420 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 4/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5139 - accuracy: 0.7906 - val_loss: 0.5439 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 5/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5141 - accuracy: 0.7906 - val_loss: 0.5425 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 6/300\n",
      "905/905 [==============================] - 42s 47ms/step - loss: 0.5137 - accuracy: 0.7906 - val_loss: 0.5447 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 7/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5138 - accuracy: 0.7906 - val_loss: 0.5429 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 8/300\n",
      "905/905 [==============================] - 42s 47ms/step - loss: 0.5139 - accuracy: 0.7906 - val_loss: 0.5429 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 9/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5138 - accuracy: 0.7906 - val_loss: 0.5417 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 10/300\n",
      "905/905 [==============================] - 41s 46ms/step - loss: 0.5136 - accuracy: 0.7906 - val_loss: 0.5429 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 11/300\n",
      "905/905 [==============================] - 43s 47ms/step - loss: 0.5138 - accuracy: 0.7906 - val_loss: 0.5413 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 12/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5138 - accuracy: 0.7906 - val_loss: 0.5419 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 13/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5139 - accuracy: 0.7906 - val_loss: 0.5447 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 14/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5139 - accuracy: 0.7906 - val_loss: 0.5458 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 15/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5139 - accuracy: 0.7906 - val_loss: 0.5444 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 16/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5138 - accuracy: 0.7906 - val_loss: 0.5472 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 17/300\n",
      "905/905 [==============================] - 41s 46ms/step - loss: 0.5135 - accuracy: 0.7906 - val_loss: 0.5433 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 18/300\n",
      "905/905 [==============================] - 43s 47ms/step - loss: 0.5136 - accuracy: 0.7906 - val_loss: 0.5413 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 19/300\n",
      "905/905 [==============================] - 41s 46ms/step - loss: 0.5138 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 20/300\n",
      "905/905 [==============================] - 41s 46ms/step - loss: 0.5136 - accuracy: 0.7906 - val_loss: 0.5429 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 21/300\n",
      "905/905 [==============================] - 41s 46ms/step - loss: 0.5136 - accuracy: 0.7906 - val_loss: 0.5415 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 22/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5139 - accuracy: 0.7906 - val_loss: 0.5421 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 23/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5135 - accuracy: 0.7906 - val_loss: 0.5456 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 24/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5136 - accuracy: 0.7906 - val_loss: 0.5442 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 25/300\n",
      "905/905 [==============================] - 42s 47ms/step - loss: 0.5136 - accuracy: 0.7906 - val_loss: 0.5440 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 26/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5136 - accuracy: 0.7906 - val_loss: 0.5417 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 27/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5136 - accuracy: 0.7906 - val_loss: 0.5430 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 28/300\n",
      "904/905 [============================>.] - ETA: 0s - loss: 0.5136 - accuracy: 0.7906\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "905/905 [==============================] - 42s 47ms/step - loss: 0.5136 - accuracy: 0.7906 - val_loss: 0.5448 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 29/300\n",
      "905/905 [==============================] - 41s 46ms/step - loss: 0.5133 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 30/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5431 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 31/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5436 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 32/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5133 - accuracy: 0.7906 - val_loss: 0.5433 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 33/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5133 - accuracy: 0.7906 - val_loss: 0.5429 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 34/300\n",
      "905/905 [==============================] - 40s 44ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5432 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 35/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5133 - accuracy: 0.7906 - val_loss: 0.5429 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 36/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5133 - accuracy: 0.7906 - val_loss: 0.5426 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 37/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5133 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 38/300\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.5132 - accuracy: 0.7906\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5428 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 39/300\n",
      "905/905 [==============================] - 40s 44ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-05\n",
      "Epoch 40/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-05\n",
      "Epoch 41/300\n",
      "905/905 [==============================] - 40s 44ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-05\n",
      "Epoch 42/300\n",
      "905/905 [==============================] - 40s 44ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-05\n",
      "Epoch 43/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-05\n",
      "Epoch 44/300\n",
      "905/905 [==============================] - 40s 44ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-05\n",
      "Epoch 45/300\n",
      "905/905 [==============================] - 39s 43ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-05\n",
      "Epoch 46/300\n",
      "905/905 [==============================] - 40s 44ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-05\n",
      "Epoch 47/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-05\n",
      "Epoch 48/300\n",
      "904/905 [============================>.] - ETA: 0s - loss: 0.5132 - accuracy: 0.7905\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
      "905/905 [==============================] - 40s 45ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-05\n",
      "Epoch 49/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-06\n",
      "Epoch 50/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-06\n",
      "Epoch 51/300\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-06\n",
      "Epoch 52/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-06\n",
      "Epoch 53/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-06\n",
      "Epoch 54/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-06\n",
      "Epoch 55/300\n",
      "905/905 [==============================] - 41s 46ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-06\n",
      "Epoch 56/300\n",
      "905/905 [==============================] - 41s 46ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-06\n",
      "Epoch 57/300\n",
      "905/905 [==============================] - 41s 45ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-06\n",
      "Epoch 58/300\n",
      "905/905 [==============================] - ETA: 0s - loss: 0.5132 - accuracy: 0.7906\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 2.000000222324161e-07.\n",
      "905/905 [==============================] - 42s 46ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-06\n",
      "Epoch 58: early stopping\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_delta=1e-8)\n",
    "earlystopper = EarlyStopping(monitor='val_loss',patience=40, verbose=1)\n",
    "check_point = K.callbacks.ModelCheckpoint(filepath=\"../../model/Resnet50_call.h5\",\n",
    "                                              monitor='val_loss',\n",
    "                                              mode=\"min\",\n",
    "                                              save_best_only=True\n",
    "                                              )\n",
    "input_t=K.Input(shape=(img_size, img_size, 3))\n",
    "input_tensor = layers.experimental.preprocessing.Resizing(img_size, img_size, interpolation=\"bilinear\", input_shape=x_train.shape[1:])(input_t)\n",
    "ResNet=EfficientNetV2B0(include_top=True,weights=\"imagenet\",input_tensor=input_tensor,classes=1280)\n",
    "model_ResNet = K.models.Sequential()\n",
    "model_ResNet.add(ResNet)\n",
    "model_ResNet.add(K.layers.Dense(64, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "model_ResNet.add(K.layers.Dense(1, activation='sigmoid'))\n",
    "model_ResNet.compile(optimizer=K.optimizers.Adam(lr=2e-3),\n",
    "                loss=tf.keras.losses.binary_crossentropy,\n",
    "                metrics=[\"accuracy\"])\n",
    "hist_ResNet = model_ResNet.fit(x_train, y_train,callbacks=[check_point,reduce_lr,earlystopper],validation_data=(x_test, y_test), epochs=300, batch_size=32,shuffle=True)\n",
    "model_ResNet.save(\"../../model/Resnet50.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
