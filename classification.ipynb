{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 11:05:10.126292: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-10 11:05:10.252211: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-10 11:05:10.722760: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda-11.6/lib64:/home/gil/anaconda3/envs/LeeYS/lib/\n",
      "2023-07-10 11:05:10.722855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda-11.6/lib64:/home/gil/anaconda3/envs/LeeYS/lib/\n",
      "2023-07-10 11:05:10.722862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "import os\n",
    "from copy import copy\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import datasets, layers, models, losses, Model\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list=glob('../../data/360umTile/*.jpg')\n",
    "img_slidename_list=copy(img_list)\n",
    "for i in range(len(img_list)):\n",
    "    img_slidename_list[i]=os.path.basename(img_list[i])[:9]\n",
    "label=pd.read_csv('../../data/P53&MMR.csv')\n",
    "img_index_list=[]\n",
    "for j in range(len(label['PathologyNumber'])):\n",
    "    img_index_list.append([i for i, ele in enumerate(img_slidename_list) if ele == label['PathologyNumber'][j]])\n",
    "label_list=copy(label['MMR status'].to_list())\n",
    "for i in range(len(label_list)):\n",
    "    if label_list[i]==\"Defect\":\n",
    "        label_list[i]=1\n",
    "    else:\n",
    "        label_list[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(img_index_list,label_list, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_x_train,list_x_test,list_y_train,list_y_test=[],[],[],[]\n",
    "for i in range(len(x_train)):\n",
    "    x_list=[]\n",
    "    if len(x_train[i])>100:                                  \n",
    "        for k in range(100):\n",
    "            a = random.randint(x_train[i][0],x_train[i][len(x_train[i])-1])       \n",
    "            while a in x_list :              # a가 이미 뽑은 리스트에 있을 때까지 다시 뽑자\n",
    "                a = random.randint(x_train[i][0],x_train[i][len(x_train[i])-1])\n",
    "            x_list.append(a) # 새로운 a 값을 리스트에 추가\n",
    "    else:\n",
    "        x_list=copy(x_train[i])\n",
    "    for j in x_list:\n",
    "        list_x_train.append(img_list[j])\n",
    "        list_y_train.append(y_train[i])\n",
    "        \n",
    "for i in range(len(x_test)):\n",
    "    x_list=[]\n",
    "    if len(x_test[i])>100:                                  \n",
    "        for k in range(100):\n",
    "            a = random.randint(x_test[i][0],x_test[i][len(x_test[i])-1])       \n",
    "            while a in x_list :              # a가 이미 뽑은 리스트에 있을 때까지 다시 뽑자\n",
    "                a = random.randint(x_test[i][0],x_test[i][len(x_test[i])-1])\n",
    "            x_list.append(a) # 새로운 a 값을 리스트에 추가\n",
    "    else:\n",
    "        x_list=copy(x_test[i])\n",
    "    for j in x_list:\n",
    "        list_x_test.append(img_list[j])\n",
    "        list_y_test.append(y_test[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=224\n",
    "x_train=np.zeros((len(list_x_train),img_size,img_size,3))\n",
    "x_test=np.zeros((len(list_x_test),img_size,img_size,3))\n",
    "y_train=np.zeros((len(list_y_train),1),dtype=np.int16)\n",
    "y_test=np.zeros((len(list_y_test),1),dtype=np.int16)\n",
    "\n",
    "for i in range(len(list_x_train)):\n",
    "    x_train[i]=Image.open(list_x_train[i])\n",
    "    y_train[i]=list_y_train[i]\n",
    "\n",
    "for i in range(len(list_x_test)):\n",
    "    x_test[i]=Image.open(list_x_test[i])\n",
    "    y_test[i]=list_y_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 11:19:53.551251: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-10 11:19:54.065796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38196 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 11:20:13.742141: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-07-10 11:20:14.622217: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905/905 [==============================] - 68s 70ms/step - loss: 0.5168 - accuracy: 0.7906 - val_loss: 0.5454 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 2/300\n",
      "905/905 [==============================] - 63s 69ms/step - loss: 0.5139 - accuracy: 0.7906 - val_loss: 0.5448 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 3/300\n",
      "905/905 [==============================] - 63s 69ms/step - loss: 0.5138 - accuracy: 0.7906 - val_loss: 0.5442 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 4/300\n",
      "905/905 [==============================] - 62s 69ms/step - loss: 0.5136 - accuracy: 0.7906 - val_loss: 0.5413 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 5/300\n",
      "905/905 [==============================] - 59s 66ms/step - loss: 0.5140 - accuracy: 0.7906 - val_loss: 0.5441 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 6/300\n",
      "905/905 [==============================] - 60s 66ms/step - loss: 0.5139 - accuracy: 0.7906 - val_loss: 0.5433 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 7/300\n",
      "905/905 [==============================] - 61s 67ms/step - loss: 0.5139 - accuracy: 0.7906 - val_loss: 0.5446 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 8/300\n",
      "905/905 [==============================] - 61s 68ms/step - loss: 0.5138 - accuracy: 0.7906 - val_loss: 0.5432 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 9/300\n",
      "905/905 [==============================] - 60s 67ms/step - loss: 0.5137 - accuracy: 0.7906 - val_loss: 0.5444 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 10/300\n",
      "905/905 [==============================] - 61s 67ms/step - loss: 0.5135 - accuracy: 0.7906 - val_loss: 0.5419 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 11/300\n",
      "905/905 [==============================] - 60s 67ms/step - loss: 0.5137 - accuracy: 0.7906 - val_loss: 0.5424 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 12/300\n",
      "905/905 [==============================] - 61s 67ms/step - loss: 0.5140 - accuracy: 0.7906 - val_loss: 0.5424 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 13/300\n",
      "905/905 [==============================] - 60s 67ms/step - loss: 0.5137 - accuracy: 0.7906 - val_loss: 0.5430 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 14/300\n",
      "904/905 [============================>.] - ETA: 0s - loss: 0.5135 - accuracy: 0.7905\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "905/905 [==============================] - 60s 67ms/step - loss: 0.5135 - accuracy: 0.7906 - val_loss: 0.5418 - val_accuracy: 0.7683 - lr: 0.0020\n",
      "Epoch 15/300\n",
      "905/905 [==============================] - 60s 66ms/step - loss: 0.5132 - accuracy: 0.7906 - val_loss: 0.5435 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 16/300\n",
      "905/905 [==============================] - 60s 66ms/step - loss: 0.5133 - accuracy: 0.7906 - val_loss: 0.5420 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 17/300\n",
      "905/905 [==============================] - 60s 66ms/step - loss: 0.5133 - accuracy: 0.7906 - val_loss: 0.5427 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 18/300\n",
      "905/905 [==============================] - 59s 65ms/step - loss: 0.5133 - accuracy: 0.7906 - val_loss: 0.5431 - val_accuracy: 0.7683 - lr: 2.0000e-04\n",
      "Epoch 19/300\n",
      "843/905 [==========================>...] - ETA: 3s - loss: 0.5139 - accuracy: 0.7901"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gil/gcubme_ai2/Workspace/YS_Lee/gcu_pathlogy/code/HistopathologyMMRstatusClassification/classification.ipynb 셀 6\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e322e35322e3638222c2275736572223a2267696c227d/home/gil/gcubme_ai2/Workspace/YS_Lee/gcu_pathlogy/code/HistopathologyMMRstatusClassification/classification.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m model_ResNet\u001b[39m.\u001b[39madd(K\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e322e35322e3638222c2275736572223a2267696c227d/home/gil/gcubme_ai2/Workspace/YS_Lee/gcu_pathlogy/code/HistopathologyMMRstatusClassification/classification.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m model_ResNet\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mK\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(lr\u001b[39m=\u001b[39m\u001b[39m2e-3\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e322e35322e3638222c2275736572223a2267696c227d/home/gil/gcubme_ai2/Workspace/YS_Lee/gcu_pathlogy/code/HistopathologyMMRstatusClassification/classification.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m                 loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mbinary_crossentropy,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e322e35322e3638222c2275736572223a2267696c227d/home/gil/gcubme_ai2/Workspace/YS_Lee/gcu_pathlogy/code/HistopathologyMMRstatusClassification/classification.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m                 metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e322e35322e3638222c2275736572223a2267696c227d/home/gil/gcubme_ai2/Workspace/YS_Lee/gcu_pathlogy/code/HistopathologyMMRstatusClassification/classification.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m hist_ResNet \u001b[39m=\u001b[39m model_ResNet\u001b[39m.\u001b[39;49mfit(x_train, y_train,callbacks\u001b[39m=\u001b[39;49m[check_point,reduce_lr,earlystopper],validation_data\u001b[39m=\u001b[39;49m(x_test, y_test), epochs\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2231302e322e35322e3638222c2275736572223a2267696c227d/home/gil/gcubme_ai2/Workspace/YS_Lee/gcu_pathlogy/code/HistopathologyMMRstatusClassification/classification.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m model_ResNet\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39m../../model/Resnet50.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/engine/training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \n\u001b[1;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[1;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/utils/tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    633\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/utils/tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    626\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 628\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    629\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_delta=1e-8)\n",
    "earlystopper = EarlyStopping(monitor='val_loss',patience=40, verbose=1)\n",
    "check_point = K.callbacks.ModelCheckpoint(filepath=\"../../model/Resnet50_call.h5\",\n",
    "                                              monitor='val_loss',\n",
    "                                              mode=\"min\",\n",
    "                                              save_best_only=True\n",
    "                                              )\n",
    "input_t=K.Input(shape=(img_size, img_size, 3))\n",
    "input_tensor = layers.experimental.preprocessing.Resizing(img_size, img_size, interpolation=\"bilinear\", input_shape=x_train.shape[1:])(input_t)\n",
    "ResNet=ResNet50(include_top=True,weights=None,input_tensor=input_tensor)\n",
    "model_ResNet = K.models.Sequential()\n",
    "model_ResNet.add(ResNet)\n",
    "model_ResNet.add(K.layers.Dense(64, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "model_ResNet.add(K.layers.Dense(1, activation='sigmoid'))\n",
    "model_ResNet.compile(optimizer=K.optimizers.Adam(lr=2e-3),\n",
    "                loss=tf.keras.losses.binary_crossentropy,\n",
    "                metrics=[\"accuracy\"])\n",
    "hist_ResNet = model_ResNet.fit(x_train, y_train,callbacks=[check_point,reduce_lr,earlystopper],validation_data=(x_test, y_test), epochs=300, batch_size=32,shuffle=True)\n",
    "model_ResNet.save(\"../../model/Resnet50.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
