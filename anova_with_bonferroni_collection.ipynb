{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from scipy.stats import ttest_ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionResNetV2_cm=np.array([[36,16],[55,127]])\n",
    "efficientNetB3_cm=np.array([[37,15],[37,145]])\n",
    "efficientNetB2_cm=np.array([[43,9],[43,139]])\n",
    "y_test=np.ones([52])\n",
    "y_test=np.concatenate([y_test,np.zeros([182])])\n",
    "\n",
    "inceptionResNetV2_pred=np.zeros([len(y_test)])\n",
    "numbers = np.random.choice(range(0, 52), 36, replace=False)\n",
    "inceptionResNetV2_pred[numbers]=1\n",
    "numbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\n",
    "inceptionResNetV2_pred[numbers]=1\n",
    "efficientNetB2_pred=np.copy(inceptionResNetV2_pred)\n",
    "ttp=np.where(efficientNetB2_pred[:52]==0)[0]\n",
    "numbers = np.random.choice(range(0, len(ttp)), 1, replace=False)\n",
    "efficientNetB2_pred[ttp[numbers]]=1\n",
    "ffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\n",
    "numbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\n",
    "efficientNetB2_pred[ffp[numbers]]=0\n",
    "efficientNetB3_pred=np.copy(inceptionResNetV2_pred)\n",
    "ttp=np.where(efficientNetB3_pred[:52]==0)[0]\n",
    "numbers = np.random.choice(range(0, len(ttp)), 43-36, replace=False)\n",
    "efficientNetB3_pred[ttp[numbers]]=1\n",
    "ffp=np.where(efficientNetB3_pred[52:]==1)[0]+52\n",
    "numbers = np.random.choice(range(0, len(ffp)), 55-43, replace=False)\n",
    "efficientNetB3_pred[ffp[numbers]]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model    Metric     Value  Alpha  Confidence Interval  \\\n",
      "0   inceptionResNetV2  Accuracy  0.696581   80.0             0.081915   \n",
      "0   inceptionResNetV2  Accuracy  0.696581   85.0             0.092056   \n",
      "0   inceptionResNetV2  Accuracy  0.696581   90.0             0.105257   \n",
      "0   inceptionResNetV2  Accuracy  0.696581   95.0             0.125575   \n",
      "0   inceptionResNetV2  Accuracy  0.696581   97.5             0.143791   \n",
      "..                ...       ...       ...    ...                  ...   \n",
      "0      efficientNetB3  F1 Score  0.623188   95.0             0.124177   \n",
      "0      efficientNetB3  F1 Score  0.623188   97.5             0.142008   \n",
      "0      efficientNetB3  F1 Score  0.623188   99.0             0.163197   \n",
      "0      efficientNetB3  F1 Score  0.623188   99.5             0.177845   \n",
      "0      efficientNetB3  F1 Score  0.623188   99.9             0.208478   \n",
      "\n",
      "     p-value  ANOVA with bonferroni collection p-value  \n",
      "0   0.000083                                  0.242462  \n",
      "0   0.000083                                  0.242462  \n",
      "0   0.000083                                  0.242462  \n",
      "0   0.000083                                  0.242462  \n",
      "0   0.000083                                  0.242462  \n",
      "..       ...                                       ...  \n",
      "0   0.000541                                  0.242462  \n",
      "0   0.000541                                  0.242462  \n",
      "0   0.000541                                  0.242462  \n",
      "0   0.000541                                  0.242462  \n",
      "0   0.000541                                  0.242462  \n",
      "\n",
      "[96 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3012593/1117742249.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_df = pd.concat([result_df, pd.DataFrame({\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t, ttest_ind, f_oneway\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 가상의 예제 데이터 생성\n",
    "data_model1 = inceptionResNetV2_pred\n",
    "data_model2 = efficientNetB2_pred\n",
    "data_model3 = efficientNetB3_pred\n",
    "\n",
    "# 이진분류 모델 3개의 결과를 각각 저장\n",
    "results_model1 = data_model1 > 0\n",
    "results_model2 = data_model2 > 0\n",
    "results_model3 = data_model3 > 0\n",
    "\n",
    "true_labels = y_test\n",
    "\n",
    "# 성능 지표 계산 함수\n",
    "def calculate_performance_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return accuracy, sensitivity, specificity, f1\n",
    "\n",
    "alpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\n",
    "\n",
    "# 결과를 저장할 DataFrame 생성\n",
    "result_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\n",
    "\n",
    "# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\n",
    "for model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\n",
    "    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\n",
    "\n",
    "    # Calculate p-value using t-test\n",
    "    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\n",
    "\n",
    "    # Perform ANOVA\n",
    "    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\n",
    "\n",
    "    # Apply Bonferroni correction to ANOVA p-value\n",
    "    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\n",
    "\n",
    "    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\n",
    "        for alpha in alpha_values:\n",
    "            # Calculate standard error of the mean\n",
    "            sem = np.std(results) / np.sqrt(len(results))\n",
    "\n",
    "            # Adjust margin_of_error and confidence_interval based on the metric\n",
    "            if metric_name == 'Accuracy':\n",
    "                margin_of_error = t.ppf(1 - alpha / 2, len(results) - 1) * sem\n",
    "            else:\n",
    "                z_score = norm.ppf(1 - alpha / 2)\n",
    "                margin_of_error = z_score * np.sqrt((metric_value * (1 - metric_value)) / len(results))\n",
    "\n",
    "            confidence_interval = (metric_value - margin_of_error, metric_value + margin_of_error)\n",
    "\n",
    "            # 결과를 DataFrame에 추가\n",
    "            result_df = pd.concat([result_df, pd.DataFrame({\n",
    "                'Model': [model],\n",
    "                'Metric': [metric_name],\n",
    "                'Value': [metric_value],\n",
    "                'Alpha': [(1 - alpha) * 100],\n",
    "                'Confidence Interval': [(confidence_interval[1] - confidence_interval[0])/2],\n",
    "                'p-value': [p_value_ttest],\n",
    "                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\n",
    "            })])\n",
    "\n",
    "# 결과 DataFrame 출력\n",
    "print(result_df)\n",
    "# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\n",
    "result_df.to_csv('model_comparison_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': '__main__',\n",
       " '__doc__': 'Automatically created module for IPython interactive environment',\n",
       " '__package__': None,\n",
       " '__loader__': None,\n",
       " '__spec__': None,\n",
       " '__builtin__': <module 'builtins' (built-in)>,\n",
       " '__builtins__': <module 'builtins' (built-in)>,\n",
       " '_ih': ['',\n",
       "  'import numpy as np \\nimport pandas as pd \\nfrom glob import glob\\nfrom scipy import stats\\nfrom sklearn.metrics import confusion_matrix, classification_report\\nfrom scipy.stats import ttest_ind',\n",
       "  'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\ninceptionResNetV2_pred[:inceptionResNetV2_cm[0,0]]=1\\ninceptionResNetV2_pred[52:52+inceptionResNetV2_cm[1,0]]=1\\nefficientNetB2_pred=np.zeros([len(y_test)])\\nefficientNetB2_pred[:efficientNetB2_cm[0,0]]=1\\nefficientNetB2_pred[52:52+efficientNetB2_cm[1,0]]=1\\nefficientNetB3_pred=np.zeros([len(y_test)])\\nefficientNetB3_pred[:efficientNetB3_cm[0,0]]=1\\nefficientNetB3_pred[52:52+efficientNetB3_cm[1,0]]=1',\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['Model 1', 'Model 2', 'Model 3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\\n\\n# Define the DeLong method\\ndef delong_roc_test(y_true, y_scores1, y_scores2, alpha=0.05):\\n    from pyCM import DeLong\\n    result = DeLong(y_true, y_scores1, y_scores2)\\n    return result.p_value, result.variance\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'DeLong p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # DeLong method\\n            auc_diff, auc_var = delong_roc_test(true_labels, results_prob, results_model1, alpha=0.05)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'DeLong p-value': [auc_diff]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\\n# Define the DeLong method\\ndef delong_roc_test(y_true, y_scores1, y_scores2, alpha=0.05):\\n    from pycm import DeLong\\n    result = DeLong(y_true, y_scores1, y_scores2)\\n    return result.p_value, result.variance\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'DeLong p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # DeLong method\\n            auc_diff, auc_var = delong_roc_test(true_labels, results_prob, results_model1, alpha=0.05)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'DeLong p-value': [auc_diff]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\\n# Define the DeLong method\\ndef delong_roc_test(y_true, y_scores1, y_scores2, alpha=0.05):\\n    from pyCM import DeLong\\n    result = DeLong(y_true, y_scores1, y_scores2)\\n    return result.p_value, result.variance\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'DeLong p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # DeLong method\\n            auc_diff, auc_var = delong_roc_test(true_labels, results_prob, results_model1, alpha=0.05)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'DeLong p-value': [auc_diff]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import (\\n    accuracy_score, precision_score, recall_score, f1_score,\\n    confusion_matrix, roc_auc_score, roc_curve\\n)\\nfrom mlxtend.evaluate import delong_test\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred_prob  # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred_prob\\ndata_model3 = efficientNetB3_pred_prob\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'DeLong p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # DeLong method\\n            auc_diff, auc_var, p_value_delong = delong_test(true_labels, results_prob, results_model1)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'DeLong p-value': [p_value_delong]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  'from pycm import DeLong',\n",
       "  'from pycm import delong_test',\n",
       "  'from pycm import delong',\n",
       "  'from pycm import DeLong',\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, wilcoxon\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import (\\n    accuracy_score, precision_score, recall_score, f1_score,\\n    confusion_matrix, roc_auc_score, roc_curve\\n)\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred_prob  # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred_prob\\ndata_model3 = efficientNetB3_pred_prob\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'Wilcoxon p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # Wilcoxon signed-rank test\\n            _, p_value_wilcoxon = wilcoxon(results_prob, results_model1)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'Wilcoxon p-value': [p_value_wilcoxon]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, wilcoxon\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import (\\n    accuracy_score, precision_score, recall_score, f1_score,\\n    confusion_matrix, roc_auc_score, roc_curve\\n)\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred  # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'Wilcoxon p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # Wilcoxon signed-rank test\\n            _, p_value_wilcoxon = wilcoxon(results_prob, results_model1)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'Wilcoxon p-value': [p_value_wilcoxon]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  'p_value_wilcoxon ',\n",
       "  'p_value_wilcoxon',\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\n\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 DataFrame에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                \\'Model\\': [model],\\n                \\'Metric\\': [metric_name],\\n                \\'Value\\': [metric_value],\\n                \\'Alpha\\': [alpha],\\n                \\'Confidence Interval\\': [confidence_interval],\\n                \\'p-value\\': [p_value_ttest],\\n                \\'ANOVA with bonferroni collection p-value\\': [p_value_anova_corrected],\\n                \\'DeLong p-value\\': [np.nan]  # Placeholder for DeLong p-value\\n            })])\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_df)):\\n    for j in range(i + 1, len(result_df)):\\n        if result_df.at[i, \\'Metric\\'] == result_df.at[j, \\'Metric\\'] and result_df.at[i, \\'Alpha\\'] == result_df.at[j, \\'Alpha\\']:\\n            metric_name = result_df.at[i, \\'Metric\\']\\n            alpha = result_df.at[i, \\'Alpha\\']\\n            model1 = result_df.at[i, \\'Model\\']\\n            model2 = result_df.at[j, \\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_df.at[i, \\'DeLong p-value\\'] = delong_p_value\\n            result_df.at[j, \\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  \"result_df.at[j, 'Metric']\",\n",
       "  \"result_df.at[j, 'Metric']\",\n",
       "  'result_df',\n",
       "  \"result_df.at[j, 'Metric']\",\n",
       "  \"result_df.at[0, 'Metric']\",\n",
       "  \"result_df.at[1, 'Metric']\",\n",
       "  \"result_df.at[0, 'Metric']\",\n",
       "  \"result_df.at[j, 'Metric']\",\n",
       "  \"result_df.at[i, 'Metric']\",\n",
       "  \"result_df.at[0, 'Metric']\",\n",
       "  \"result_df.loc[0, 'Metric']\",\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\n\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\n\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\nresult_list = []\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\nrom scipy.stats import norm\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\nresult_list = []\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\nfrom scipy.stats import norm\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\nresult_list = []\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\nfrom scipy.stats import norm\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\nresult_list = []\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'inceptionResNetV2\\', \\'efficientNetB2\\', \\'efficientNetB3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': '±'+str(metric_value-confidence_interval[0]),\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': '±'+str(metric_value-confidence_interval[0]),\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv',encoding='cp949', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\n\\n# CSV 파일에서 데이터 읽기\\ncsv_file = 'model_comparison_results.csv'\\ndf = pd.read_csv(csv_file)\\n\\n# 데이터를 원하는 형식으로 가공\\ntable = df.pivot_table(index=['Model', 'Metric'], columns='Alpha', values=['Value', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 워드 논문 형식에 맞게 컬럼 정렬\\ntable = table[[('Value', 0.2), ('Value', 0.15), ('Value', 0.1), ('Value', 0.05), ('Value', 0.025), ('Value', 0.01), ('Value', 0.005), ('Value', 0.001),\\n               ('Confidence Interval', 0.2), ('Confidence Interval', 0.15), ('Confidence Interval', 0.1), ('Confidence Interval', 0.05), ('Confidence Interval', 0.025), ('Confidence Interval', 0.01), ('Confidence Interval', 0.005), ('Confidence Interval', 0.001),\\n               ('p-value', 0.2), ('p-value', 0.15), ('p-value', 0.1), ('p-value', 0.05), ('p-value', 0.025), ('p-value', 0.01), ('p-value', 0.005), ('p-value', 0.001),\\n               ('ANOVA with bonferroni collection p-value', 0.2), ('ANOVA with bonferroni collection p-value', 0.15), ('ANOVA with bonferroni collection p-value', 0.1), ('ANOVA with bonferroni collection p-value', 0.05), ('ANOVA with bonferroni collection p-value', 0.025), ('ANOVA with bonferroni collection p-value', 0.01), ('ANOVA with bonferroni collection p-value', 0.005), ('ANOVA with bonferroni collection p-value', 0.001)]]\\n\\n# 워드 표 형식으로 출력\\nprint(table.to_markdown())\",\n",
       "  \"import pandas as pd\\n\\n# CSV 파일에서 데이터 읽기\\ncsv_file = 'model_comparison_results.csv'\\ndf = pd.read_csv(csv_file)\\n\\n# 데이터를 원하는 형식으로 가공\\ntable = df.pivot_table(index=['Model', 'Metric'], columns='Alpha', values=['Value', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 워드 논문 형식에 맞게 컬럼 정렬\\ntable = table[[('Value'),\\n               ('Confidence Interval', 0.2), ('Confidence Interval', 0.15), ('Confidence Interval', 0.1), ('Confidence Interval', 0.05), ('Confidence Interval', 0.025), ('Confidence Interval', 0.01), ('Confidence Interval', 0.005), ('Confidence Interval', 0.001),\\n               ('p-value', 0.2), ('p-value', 0.15), ('p-value', 0.1), ('p-value', 0.05), ('p-value', 0.025), ('p-value', 0.01), ('p-value', 0.005), ('p-value', 0.001),\\n               ('ANOVA with bonferroni collection p-value', 0.2), ('ANOVA with bonferroni collection p-value', 0.15), ('ANOVA with bonferroni collection p-value', 0.1), ('ANOVA with bonferroni collection p-value', 0.05), ('ANOVA with bonferroni collection p-value', 0.025), ('ANOVA with bonferroni collection p-value', 0.01), ('ANOVA with bonferroni collection p-value', 0.005), ('ANOVA with bonferroni collection p-value', 0.001)]]\\n\\n# 워드 표 형식으로 출력\\nprint(table.to_markdown())\",\n",
       "  \"import pandas as pd\\n\\n# CSV 파일에서 데이터 읽기\\ncsv_file = 'model_comparison_results.csv'\\ndf = pd.read_csv(csv_file)\\n\\n# 데이터를 원하는 형식으로 가공\\ntable = df.pivot_table(index=['Model', 'Metric'], columns='Alpha', values=['Value', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 워드 논문 형식에 맞게 컬럼 정렬\\ntable = table[[('Value', 0.2),\\n               ('Confidence Interval', 0.2), ('Confidence Interval', 0.15), ('Confidence Interval', 0.1), ('Confidence Interval', 0.05), ('Confidence Interval', 0.025), ('Confidence Interval', 0.01), ('Confidence Interval', 0.005), ('Confidence Interval', 0.001),\\n               ('p-value', 0.2), ('p-value', 0.15), ('p-value', 0.1), ('p-value', 0.05), ('p-value', 0.025), ('p-value', 0.01), ('p-value', 0.005), ('p-value', 0.001),\\n               ('ANOVA with bonferroni collection p-value', 0.2), ('ANOVA with bonferroni collection p-value', 0.15), ('ANOVA with bonferroni collection p-value', 0.1), ('ANOVA with bonferroni collection p-value', 0.05), ('ANOVA with bonferroni collection p-value', 0.025), ('ANOVA with bonferroni collection p-value', 0.01), ('ANOVA with bonferroni collection p-value', 0.005), ('ANOVA with bonferroni collection p-value', 0.001)]]\\n\\n# 워드 표 형식으로 출력\\nprint(table.to_markdown())\",\n",
       "  \"import pandas as pd\\n\\n# CSV 파일에서 데이터 읽기\\ncsv_file = 'model_comparison_results.csv'\\ndf = pd.read_csv(csv_file)\\n\\n# 데이터를 원하는 형식으로 가공\\ntable = df.pivot_table(index=['Model', 'Metric'], columns='Alpha', values=['Value', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 워드 논문 형식에 맞게 컬럼 정렬\\ntable = table[[('Value', 0.2),\\n               ('Confidence Interval', 0.2), ('Confidence Interval', 0.15), ('Confidence Interval', 0.1), ('Confidence Interval', 0.05), ('Confidence Interval', 0.025), ('Confidence Interval', 0.01), ('Confidence Interval', 0.005), ('Confidence Interval', 0.001),\\n               ('p-value', 0.2),\\n               ('ANOVA with bonferroni collection p-value', 0.2), ('ANOVA with bonferroni collection p-value', 0.15), ('ANOVA with bonferroni collection p-value', 0.1), ('ANOVA with bonferroni collection p-value', 0.05), ('ANOVA with bonferroni collection p-value', 0.025), ('ANOVA with bonferroni collection p-value', 0.01), ('ANOVA with bonferroni collection p-value', 0.005), ('ANOVA with bonferroni collection p-value', 0.001)]]\\n\\n# 워드 표 형식으로 출력\\nprint(table.to_markdown())\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False) \",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False) \",\n",
       "  'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=inceptionResNetV2_pred',\n",
       "  'np.where(efficientNetB2_pred[:52]==0)[0]',\n",
       "  'efficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)',\n",
       "  'ffp=np.where(efficientNetB2_pred[52:]==1)[0]\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)',\n",
       "  'ffp=np.where(efficientNetB2_pred[52:]==1)[0]\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nffp',\n",
       "  'ffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)',\n",
       "  'ffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nffp',\n",
       "  'ffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nffp[numbers]',\n",
       "  'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB2_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 1, replace=False)\\nefficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nefficientNetB2_pred[ffp[numbers]]=0',\n",
       "  'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB2_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 1, replace=False)\\nefficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nefficientNetB2_pred[ffp[numbers]]=0\\nefficientNetB3_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB3_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 43-36, replace=False)\\nefficientNetB3_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB3_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-43, replace=False)\\nefficientNetB3_pred[ffp[numbers]]=0',\n",
       "  'efficientNetB3_pred',\n",
       "  'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB2_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 1, replace=False)\\nefficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nefficientNetB2_pred[ffp[numbers]]=0\\nefficientNetB3_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB3_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 43-36, replace=False)\\nefficientNetB3_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB3_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-43, replace=False)\\nefficientNetB3_pred[ffp[numbers]]=0',\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False) \",\n",
       "  'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=np.copy(inceptionResNetV2_pred)\\nttp=np.where(efficientNetB2_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 1, replace=False)\\nefficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nefficientNetB2_pred[ffp[numbers]]=0\\nefficientNetB3_pred=np.copy(inceptionResNetV2_pred)\\nttp=np.where(efficientNetB3_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 43-36, replace=False)\\nefficientNetB3_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB3_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-43, replace=False)\\nefficientNetB3_pred[ffp[numbers]]=0',\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False) \",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    \\n    metrics = {\\n        'Accuracy': accuracy,\\n        'Sensitivity': sensitivity,\\n        'Specificity': specificity,\\n        'F1 Score': f1\\n    }\\n\\n    return metrics\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    for metric_name, metric_value in calculate_performance_metrics(true_labels, results).items():\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    \\n    metrics = {\\n        'Accuracy': accuracy,\\n        'Sensitivity': sensitivity,\\n        'Specificity': specificity,\\n        'F1 Score': f1\\n    }\\n\\n    return metrics\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    for metric_name, metric_value in calculate_performance_metrics(true_labels, results).items():\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  'confidence_interval',\n",
       "  'metric_value',\n",
       "  'metric_name',\n",
       "  \"for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n    print(metric_name)\",\n",
       "  \"for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n    print(metric_value)\",\n",
       "  \"for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n    for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\",\n",
       "  \"for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n    for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            print(confidence_interval)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 2\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\nimport numpy as np\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, metric_name):\\n    if metric_name == \\'Accuracy\\':\\n        metric_value = accuracy_score(y_true, y_pred)\\n    elif metric_name == \\'Sensitivity\\':\\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n        metric_value = tp / (tp + fn)\\n    elif metric_name == \\'Specificity\\':\\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n        metric_value = tn / (tn + fp)\\n    elif metric_name == \\'F1 Score\\':\\n        metric_value = f1_score(y_true, y_pred)\\n    else:\\n        raise ValueError(\"Invalid metric name\")\\n\\n    return metric_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip([\\'inceptionResNetV2\\', \\'efficientNetB2\\', \\'efficientNetB3\\'], [results_model1, results_model2, results_model3]):\\n    for metric_name in [\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\']:\\n        metric_value = calculate_performance_metrics(true_labels, results, metric_name)\\n\\n        # Calculate p-value using t-test\\n        t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n        # Perform ANOVA\\n        _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n        # Apply Bonferroni correction to ANOVA p-value\\n        _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                \\'Model\\': [model],\\n                \\'Metric\\': [metric_name],\\n                \\'Value\\': [metric_value],\\n                \\'Alpha\\': [(1-alpha)*100],\\n                \\'Confidence Interval\\': [confidence_interval[1] - confidence_interval[0]],\\n                \\'p-value\\': [p_value_ttest],\\n                \\'ANOVA with bonferroni collection p-value\\': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\nimport numpy as np\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, metric_name):\\n    if metric_name == \\'Accuracy\\':\\n        metric_value = accuracy_score(y_true, y_pred)\\n    elif metric_name == \\'Sensitivity\\':\\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n        metric_value = tp / (tp + fn)\\n    elif metric_name == \\'Specificity\\':\\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n        metric_value = tn / (tn + fp)\\n    elif metric_name == \\'F1 Score\\':\\n        metric_value = f1_score(y_true, y_pred)\\n    else:\\n        raise ValueError(\"Invalid metric name\")\\n\\n    return metric_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip([\\'inceptionResNetV2\\', \\'efficientNetB2\\', \\'efficientNetB3\\'], [results_model1, results_model2, results_model3]):\\n    for metric_name in [\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\']:\\n        metric_value = calculate_performance_metrics(true_labels, results, metric_name)\\n\\n        # Calculate p-value using t-test\\n        t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n        # Perform ANOVA\\n        _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n        # Apply Bonferroni correction to ANOVA p-value\\n        _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                \\'Model\\': [model],\\n                \\'Metric\\': [metric_name],\\n                \\'Value\\': [metric_value],\\n                \\'Alpha\\': [(1-alpha)*100],\\n                \\'Confidence Interval\\': [confidence_interval[1] - confidence_interval[0]],\\n                \\'p-value\\': [p_value_ttest],\\n                \\'ANOVA with bonferroni collection p-value\\': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n\\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n\\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # Calculate standard error of the mean\\n            sem = np.std(results) / np.sqrt(len(results))\\n\\n            # Calculate confidence interval manually\\n            margin_of_error = t.ppf(1 - alpha / 2, len(results) - 1) * sem\\n            confidence_interval = (metric_value - margin_of_error, metric_value + margin_of_error)\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1 - alpha) * 100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n\\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n\\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # Calculate standard error of the mean\\n            sem = np.std(results) / np.sqrt(len(results))\\n\\n            # Calculate confidence interval manually\\n            margin_of_error = t.ppf(1 - alpha / 2, len(results) - 1) * sem\\n            confidence_interval = (metric_value - margin_of_error, metric_value + margin_of_error)\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1 - alpha) * 100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  'sem = np.std(results) / np.sqrt(len(results))',\n",
       "  'sem ',\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n\\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n\\n    metrics = ['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score']\\n    \\n    for metric_name in metrics:\\n        metric_value = locals()[metric_name.lower()]  # Access the metric value dynamically\\n\\n        for alpha in alpha_values:\\n            # Calculate standard error of the mean\\n            sem = np.std(results) / np.sqrt(len(results))\\n\\n            # Calculate t-statistic for the given alpha\\n            t_value = t.ppf(1 - alpha / 2, len(results) - 1)\\n\\n            # Calculate lower and upper bounds of the confidence interval\\n            lower_bound = metric_value - t_value * sem\\n            upper_bound = metric_value + t_value * sem\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1 - alpha) * 100],\\n                'Confidence Interval': [upper_bound - lower_bound],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  'metrics',\n",
       "  'metricsmetric_name.lower(',\n",
       "  'metricsmetric_name.lower',\n",
       "  'metricsmetric_name.lower',\n",
       "  'locals()'],\n",
       " '_oh': {19:       Model    Metric     Value  Alpha  \\\n",
       "  0   Model 1  Accuracy  0.696581  0.200   \n",
       "  0   Model 1  Accuracy  0.696581  0.150   \n",
       "  0   Model 1  Accuracy  0.696581  0.100   \n",
       "  0   Model 1  Accuracy  0.696581  0.050   \n",
       "  0   Model 1  Accuracy  0.696581  0.025   \n",
       "  ..      ...       ...       ...    ...   \n",
       "  0   Model 3       AUC  0.754121  0.050   \n",
       "  0   Model 3       AUC  0.754121  0.025   \n",
       "  0   Model 3       AUC  0.754121  0.010   \n",
       "  0   Model 3       AUC  0.754121  0.005   \n",
       "  0   Model 3       AUC  0.754121  0.001   \n",
       "  \n",
       "                           Confidence Interval   p-value  \\\n",
       "  0   (0.6556236315641998, 0.7375387615981933)  0.000083   \n",
       "  0   (0.6505534040262204, 0.7426089891361727)  0.000083   \n",
       "  0   (0.6439525289011624, 0.7492098642612307)  0.000083   \n",
       "  0   (0.6337934763835406, 0.7593689167788525)  0.000083   \n",
       "  0   (0.6246859388785894, 0.7684764542838038)  0.000083   \n",
       "  ..                                       ...       ...   \n",
       "  0    (0.694229839681716, 0.8140119185600424)  0.021846   \n",
       "  0   (0.6855424739645728, 0.8226992842771856)  0.021846   \n",
       "  0   (0.6751731313298386, 0.8330686269119199)  0.021846   \n",
       "  0     (0.66797107582275, 0.8402706824190087)  0.021846   \n",
       "  0   (0.6528096657757041, 0.8554320924660553)  0.021846   \n",
       "  \n",
       "     ANOVA with bonferroni collection p-value DeLong p-value  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  ..                                      ...            ...  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  \n",
       "  [120 rows x 8 columns],\n",
       "  21: 0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "         ...   \n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  Name: Metric, Length: 120, dtype: object,\n",
       "  23: 0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "         ...   \n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  Name: Metric, Length: 120, dtype: object,\n",
       "  25: 0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "         ...   \n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  Name: Metric, Length: 120, dtype: object,\n",
       "  26: 0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "         ...   \n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  Name: Metric, Length: 120, dtype: object,\n",
       "  27: 0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "         ...   \n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  Name: Metric, Length: 120, dtype: object,\n",
       "  49: array([ 0,  3,  4,  7,  8, 11, 17, 34, 36, 39, 40, 42, 45, 47, 48, 50]),\n",
       "  52: array([  0,   3,   6,  11,  13,  14,  15,  16,  17,  19,  32,  35,  36,\n",
       "          38,  39,  41,  46,  48,  57,  60,  68,  69,  73,  74,  75,  79,\n",
       "          80,  81,  82,  86,  96,  99, 102, 105, 108, 109, 111, 112, 113,\n",
       "         115, 117, 121, 124, 133, 138, 141, 143, 145, 148, 156, 160, 169,\n",
       "         171, 177, 180]),\n",
       "  54: array([ 52,  55,  58,  63,  65,  66,  67,  68,  69,  71,  84,  87,  88,\n",
       "          90,  91,  93,  98, 100, 109, 112, 120, 121, 125, 126, 127, 131,\n",
       "         132, 133, 134, 138, 148, 151, 154, 157, 160, 161, 163, 164, 165,\n",
       "         167, 169, 173, 176, 185, 190, 193, 195, 197, 200, 208, 212, 221,\n",
       "         223, 229, 232]),\n",
       "  55: array([160, 173, 190, 154, 223, 134,  65, 100,  84, 126,  88, 109, 138,\n",
       "         176,  67, 121,  98, 157]),\n",
       "  58: array([0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "         1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       "  68: (0.5181467040987666, 0.7282301074954373),\n",
       "  69: 0.6231884057971014,\n",
       "  70: 'F1 Score',\n",
       "  84: 0.031517829165165843,\n",
       "  86: ['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score']},\n",
       " '_dh': [PosixPath('/home/gil/gcubme_ai2/Workspace/YS_Lee/gcu_pathlogy/code/HistopathologyMMRstatusClassification'),\n",
       "  PosixPath('/home/gil/gcubme_ai2/Workspace/YS_Lee/gcu_pathlogy/code/HistopathologyMMRstatusClassification')],\n",
       " 'In': ['',\n",
       "  'import numpy as np \\nimport pandas as pd \\nfrom glob import glob\\nfrom scipy import stats\\nfrom sklearn.metrics import confusion_matrix, classification_report\\nfrom scipy.stats import ttest_ind',\n",
       "  'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\ninceptionResNetV2_pred[:inceptionResNetV2_cm[0,0]]=1\\ninceptionResNetV2_pred[52:52+inceptionResNetV2_cm[1,0]]=1\\nefficientNetB2_pred=np.zeros([len(y_test)])\\nefficientNetB2_pred[:efficientNetB2_cm[0,0]]=1\\nefficientNetB2_pred[52:52+efficientNetB2_cm[1,0]]=1\\nefficientNetB3_pred=np.zeros([len(y_test)])\\nefficientNetB3_pred[:efficientNetB3_cm[0,0]]=1\\nefficientNetB3_pred[52:52+efficientNetB3_cm[1,0]]=1',\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['Model 1', 'Model 2', 'Model 3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\\n\\n# Define the DeLong method\\ndef delong_roc_test(y_true, y_scores1, y_scores2, alpha=0.05):\\n    from pyCM import DeLong\\n    result = DeLong(y_true, y_scores1, y_scores2)\\n    return result.p_value, result.variance\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'DeLong p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # DeLong method\\n            auc_diff, auc_var = delong_roc_test(true_labels, results_prob, results_model1, alpha=0.05)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'DeLong p-value': [auc_diff]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\\n# Define the DeLong method\\ndef delong_roc_test(y_true, y_scores1, y_scores2, alpha=0.05):\\n    from pycm import DeLong\\n    result = DeLong(y_true, y_scores1, y_scores2)\\n    return result.p_value, result.variance\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'DeLong p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # DeLong method\\n            auc_diff, auc_var = delong_roc_test(true_labels, results_prob, results_model1, alpha=0.05)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'DeLong p-value': [auc_diff]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\\n# Define the DeLong method\\ndef delong_roc_test(y_true, y_scores1, y_scores2, alpha=0.05):\\n    from pyCM import DeLong\\n    result = DeLong(y_true, y_scores1, y_scores2)\\n    return result.p_value, result.variance\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'DeLong p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # DeLong method\\n            auc_diff, auc_var = delong_roc_test(true_labels, results_prob, results_model1, alpha=0.05)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'DeLong p-value': [auc_diff]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import (\\n    accuracy_score, precision_score, recall_score, f1_score,\\n    confusion_matrix, roc_auc_score, roc_curve\\n)\\nfrom mlxtend.evaluate import delong_test\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred_prob  # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred_prob\\ndata_model3 = efficientNetB3_pred_prob\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'DeLong p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # DeLong method\\n            auc_diff, auc_var, p_value_delong = delong_test(true_labels, results_prob, results_model1)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'DeLong p-value': [p_value_delong]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  'from pycm import DeLong',\n",
       "  'from pycm import delong_test',\n",
       "  'from pycm import delong',\n",
       "  'from pycm import DeLong',\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, wilcoxon\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import (\\n    accuracy_score, precision_score, recall_score, f1_score,\\n    confusion_matrix, roc_auc_score, roc_curve\\n)\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred_prob  # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred_prob\\ndata_model3 = efficientNetB3_pred_prob\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'Wilcoxon p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # Wilcoxon signed-rank test\\n            _, p_value_wilcoxon = wilcoxon(results_prob, results_model1)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'Wilcoxon p-value': [p_value_wilcoxon]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, wilcoxon\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import (\\n    accuracy_score, precision_score, recall_score, f1_score,\\n    confusion_matrix, roc_auc_score, roc_curve\\n)\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred  # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'Wilcoxon p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # Wilcoxon signed-rank test\\n            _, p_value_wilcoxon = wilcoxon(results_prob, results_model1)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'Wilcoxon p-value': [p_value_wilcoxon]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  'p_value_wilcoxon ',\n",
       "  'p_value_wilcoxon',\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\n\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 DataFrame에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                \\'Model\\': [model],\\n                \\'Metric\\': [metric_name],\\n                \\'Value\\': [metric_value],\\n                \\'Alpha\\': [alpha],\\n                \\'Confidence Interval\\': [confidence_interval],\\n                \\'p-value\\': [p_value_ttest],\\n                \\'ANOVA with bonferroni collection p-value\\': [p_value_anova_corrected],\\n                \\'DeLong p-value\\': [np.nan]  # Placeholder for DeLong p-value\\n            })])\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_df)):\\n    for j in range(i + 1, len(result_df)):\\n        if result_df.at[i, \\'Metric\\'] == result_df.at[j, \\'Metric\\'] and result_df.at[i, \\'Alpha\\'] == result_df.at[j, \\'Alpha\\']:\\n            metric_name = result_df.at[i, \\'Metric\\']\\n            alpha = result_df.at[i, \\'Alpha\\']\\n            model1 = result_df.at[i, \\'Model\\']\\n            model2 = result_df.at[j, \\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_df.at[i, \\'DeLong p-value\\'] = delong_p_value\\n            result_df.at[j, \\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  \"result_df.at[j, 'Metric']\",\n",
       "  \"result_df.at[j, 'Metric']\",\n",
       "  'result_df',\n",
       "  \"result_df.at[j, 'Metric']\",\n",
       "  \"result_df.at[0, 'Metric']\",\n",
       "  \"result_df.at[1, 'Metric']\",\n",
       "  \"result_df.at[0, 'Metric']\",\n",
       "  \"result_df.at[j, 'Metric']\",\n",
       "  \"result_df.at[i, 'Metric']\",\n",
       "  \"result_df.at[0, 'Metric']\",\n",
       "  \"result_df.loc[0, 'Metric']\",\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\n\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\n\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\nresult_list = []\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\nrom scipy.stats import norm\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\nresult_list = []\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\nfrom scipy.stats import norm\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\nresult_list = []\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\nfrom scipy.stats import norm\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\nresult_list = []\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'inceptionResNetV2\\', \\'efficientNetB2\\', \\'efficientNetB3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': '±'+str(metric_value-confidence_interval[0]),\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': '±'+str(metric_value-confidence_interval[0]),\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv',encoding='cp949', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\n\\n# CSV 파일에서 데이터 읽기\\ncsv_file = 'model_comparison_results.csv'\\ndf = pd.read_csv(csv_file)\\n\\n# 데이터를 원하는 형식으로 가공\\ntable = df.pivot_table(index=['Model', 'Metric'], columns='Alpha', values=['Value', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 워드 논문 형식에 맞게 컬럼 정렬\\ntable = table[[('Value', 0.2), ('Value', 0.15), ('Value', 0.1), ('Value', 0.05), ('Value', 0.025), ('Value', 0.01), ('Value', 0.005), ('Value', 0.001),\\n               ('Confidence Interval', 0.2), ('Confidence Interval', 0.15), ('Confidence Interval', 0.1), ('Confidence Interval', 0.05), ('Confidence Interval', 0.025), ('Confidence Interval', 0.01), ('Confidence Interval', 0.005), ('Confidence Interval', 0.001),\\n               ('p-value', 0.2), ('p-value', 0.15), ('p-value', 0.1), ('p-value', 0.05), ('p-value', 0.025), ('p-value', 0.01), ('p-value', 0.005), ('p-value', 0.001),\\n               ('ANOVA with bonferroni collection p-value', 0.2), ('ANOVA with bonferroni collection p-value', 0.15), ('ANOVA with bonferroni collection p-value', 0.1), ('ANOVA with bonferroni collection p-value', 0.05), ('ANOVA with bonferroni collection p-value', 0.025), ('ANOVA with bonferroni collection p-value', 0.01), ('ANOVA with bonferroni collection p-value', 0.005), ('ANOVA with bonferroni collection p-value', 0.001)]]\\n\\n# 워드 표 형식으로 출력\\nprint(table.to_markdown())\",\n",
       "  \"import pandas as pd\\n\\n# CSV 파일에서 데이터 읽기\\ncsv_file = 'model_comparison_results.csv'\\ndf = pd.read_csv(csv_file)\\n\\n# 데이터를 원하는 형식으로 가공\\ntable = df.pivot_table(index=['Model', 'Metric'], columns='Alpha', values=['Value', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 워드 논문 형식에 맞게 컬럼 정렬\\ntable = table[[('Value'),\\n               ('Confidence Interval', 0.2), ('Confidence Interval', 0.15), ('Confidence Interval', 0.1), ('Confidence Interval', 0.05), ('Confidence Interval', 0.025), ('Confidence Interval', 0.01), ('Confidence Interval', 0.005), ('Confidence Interval', 0.001),\\n               ('p-value', 0.2), ('p-value', 0.15), ('p-value', 0.1), ('p-value', 0.05), ('p-value', 0.025), ('p-value', 0.01), ('p-value', 0.005), ('p-value', 0.001),\\n               ('ANOVA with bonferroni collection p-value', 0.2), ('ANOVA with bonferroni collection p-value', 0.15), ('ANOVA with bonferroni collection p-value', 0.1), ('ANOVA with bonferroni collection p-value', 0.05), ('ANOVA with bonferroni collection p-value', 0.025), ('ANOVA with bonferroni collection p-value', 0.01), ('ANOVA with bonferroni collection p-value', 0.005), ('ANOVA with bonferroni collection p-value', 0.001)]]\\n\\n# 워드 표 형식으로 출력\\nprint(table.to_markdown())\",\n",
       "  \"import pandas as pd\\n\\n# CSV 파일에서 데이터 읽기\\ncsv_file = 'model_comparison_results.csv'\\ndf = pd.read_csv(csv_file)\\n\\n# 데이터를 원하는 형식으로 가공\\ntable = df.pivot_table(index=['Model', 'Metric'], columns='Alpha', values=['Value', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 워드 논문 형식에 맞게 컬럼 정렬\\ntable = table[[('Value', 0.2),\\n               ('Confidence Interval', 0.2), ('Confidence Interval', 0.15), ('Confidence Interval', 0.1), ('Confidence Interval', 0.05), ('Confidence Interval', 0.025), ('Confidence Interval', 0.01), ('Confidence Interval', 0.005), ('Confidence Interval', 0.001),\\n               ('p-value', 0.2), ('p-value', 0.15), ('p-value', 0.1), ('p-value', 0.05), ('p-value', 0.025), ('p-value', 0.01), ('p-value', 0.005), ('p-value', 0.001),\\n               ('ANOVA with bonferroni collection p-value', 0.2), ('ANOVA with bonferroni collection p-value', 0.15), ('ANOVA with bonferroni collection p-value', 0.1), ('ANOVA with bonferroni collection p-value', 0.05), ('ANOVA with bonferroni collection p-value', 0.025), ('ANOVA with bonferroni collection p-value', 0.01), ('ANOVA with bonferroni collection p-value', 0.005), ('ANOVA with bonferroni collection p-value', 0.001)]]\\n\\n# 워드 표 형식으로 출력\\nprint(table.to_markdown())\",\n",
       "  \"import pandas as pd\\n\\n# CSV 파일에서 데이터 읽기\\ncsv_file = 'model_comparison_results.csv'\\ndf = pd.read_csv(csv_file)\\n\\n# 데이터를 원하는 형식으로 가공\\ntable = df.pivot_table(index=['Model', 'Metric'], columns='Alpha', values=['Value', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 워드 논문 형식에 맞게 컬럼 정렬\\ntable = table[[('Value', 0.2),\\n               ('Confidence Interval', 0.2), ('Confidence Interval', 0.15), ('Confidence Interval', 0.1), ('Confidence Interval', 0.05), ('Confidence Interval', 0.025), ('Confidence Interval', 0.01), ('Confidence Interval', 0.005), ('Confidence Interval', 0.001),\\n               ('p-value', 0.2),\\n               ('ANOVA with bonferroni collection p-value', 0.2), ('ANOVA with bonferroni collection p-value', 0.15), ('ANOVA with bonferroni collection p-value', 0.1), ('ANOVA with bonferroni collection p-value', 0.05), ('ANOVA with bonferroni collection p-value', 0.025), ('ANOVA with bonferroni collection p-value', 0.01), ('ANOVA with bonferroni collection p-value', 0.005), ('ANOVA with bonferroni collection p-value', 0.001)]]\\n\\n# 워드 표 형식으로 출력\\nprint(table.to_markdown())\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False) \",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False) \",\n",
       "  'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=inceptionResNetV2_pred',\n",
       "  'np.where(efficientNetB2_pred[:52]==0)[0]',\n",
       "  'efficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)',\n",
       "  'ffp=np.where(efficientNetB2_pred[52:]==1)[0]\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)',\n",
       "  'ffp=np.where(efficientNetB2_pred[52:]==1)[0]\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nffp',\n",
       "  'ffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)',\n",
       "  'ffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nffp',\n",
       "  'ffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nffp[numbers]',\n",
       "  'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB2_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 1, replace=False)\\nefficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nefficientNetB2_pred[ffp[numbers]]=0',\n",
       "  'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB2_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 1, replace=False)\\nefficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nefficientNetB2_pred[ffp[numbers]]=0\\nefficientNetB3_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB3_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 43-36, replace=False)\\nefficientNetB3_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB3_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-43, replace=False)\\nefficientNetB3_pred[ffp[numbers]]=0',\n",
       "  'efficientNetB3_pred',\n",
       "  'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB2_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 1, replace=False)\\nefficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nefficientNetB2_pred[ffp[numbers]]=0\\nefficientNetB3_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB3_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 43-36, replace=False)\\nefficientNetB3_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB3_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-43, replace=False)\\nefficientNetB3_pred[ffp[numbers]]=0',\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False) \",\n",
       "  'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=np.copy(inceptionResNetV2_pred)\\nttp=np.where(efficientNetB2_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 1, replace=False)\\nefficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nefficientNetB2_pred[ffp[numbers]]=0\\nefficientNetB3_pred=np.copy(inceptionResNetV2_pred)\\nttp=np.where(efficientNetB3_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 43-36, replace=False)\\nefficientNetB3_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB3_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-43, replace=False)\\nefficientNetB3_pred[ffp[numbers]]=0',\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False) \",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    \\n    metrics = {\\n        'Accuracy': accuracy,\\n        'Sensitivity': sensitivity,\\n        'Specificity': specificity,\\n        'F1 Score': f1\\n    }\\n\\n    return metrics\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    for metric_name, metric_value in calculate_performance_metrics(true_labels, results).items():\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    \\n    metrics = {\\n        'Accuracy': accuracy,\\n        'Sensitivity': sensitivity,\\n        'Specificity': specificity,\\n        'F1 Score': f1\\n    }\\n\\n    return metrics\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    for metric_name, metric_value in calculate_performance_metrics(true_labels, results).items():\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  'confidence_interval',\n",
       "  'metric_value',\n",
       "  'metric_name',\n",
       "  \"for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n    print(metric_name)\",\n",
       "  \"for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n    print(metric_value)\",\n",
       "  \"for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n    for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\",\n",
       "  \"for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n    for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            print(confidence_interval)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 2\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\nimport numpy as np\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, metric_name):\\n    if metric_name == \\'Accuracy\\':\\n        metric_value = accuracy_score(y_true, y_pred)\\n    elif metric_name == \\'Sensitivity\\':\\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n        metric_value = tp / (tp + fn)\\n    elif metric_name == \\'Specificity\\':\\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n        metric_value = tn / (tn + fp)\\n    elif metric_name == \\'F1 Score\\':\\n        metric_value = f1_score(y_true, y_pred)\\n    else:\\n        raise ValueError(\"Invalid metric name\")\\n\\n    return metric_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip([\\'inceptionResNetV2\\', \\'efficientNetB2\\', \\'efficientNetB3\\'], [results_model1, results_model2, results_model3]):\\n    for metric_name in [\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\']:\\n        metric_value = calculate_performance_metrics(true_labels, results, metric_name)\\n\\n        # Calculate p-value using t-test\\n        t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n        # Perform ANOVA\\n        _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n        # Apply Bonferroni correction to ANOVA p-value\\n        _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                \\'Model\\': [model],\\n                \\'Metric\\': [metric_name],\\n                \\'Value\\': [metric_value],\\n                \\'Alpha\\': [(1-alpha)*100],\\n                \\'Confidence Interval\\': [confidence_interval[1] - confidence_interval[0]],\\n                \\'p-value\\': [p_value_ttest],\\n                \\'ANOVA with bonferroni collection p-value\\': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\nimport numpy as np\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, metric_name):\\n    if metric_name == \\'Accuracy\\':\\n        metric_value = accuracy_score(y_true, y_pred)\\n    elif metric_name == \\'Sensitivity\\':\\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n        metric_value = tp / (tp + fn)\\n    elif metric_name == \\'Specificity\\':\\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n        metric_value = tn / (tn + fp)\\n    elif metric_name == \\'F1 Score\\':\\n        metric_value = f1_score(y_true, y_pred)\\n    else:\\n        raise ValueError(\"Invalid metric name\")\\n\\n    return metric_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip([\\'inceptionResNetV2\\', \\'efficientNetB2\\', \\'efficientNetB3\\'], [results_model1, results_model2, results_model3]):\\n    for metric_name in [\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\']:\\n        metric_value = calculate_performance_metrics(true_labels, results, metric_name)\\n\\n        # Calculate p-value using t-test\\n        t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n        # Perform ANOVA\\n        _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n        # Apply Bonferroni correction to ANOVA p-value\\n        _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                \\'Model\\': [model],\\n                \\'Metric\\': [metric_name],\\n                \\'Value\\': [metric_value],\\n                \\'Alpha\\': [(1-alpha)*100],\\n                \\'Confidence Interval\\': [confidence_interval[1] - confidence_interval[0]],\\n                \\'p-value\\': [p_value_ttest],\\n                \\'ANOVA with bonferroni collection p-value\\': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n\\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n\\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # Calculate standard error of the mean\\n            sem = np.std(results) / np.sqrt(len(results))\\n\\n            # Calculate confidence interval manually\\n            margin_of_error = t.ppf(1 - alpha / 2, len(results) - 1) * sem\\n            confidence_interval = (metric_value - margin_of_error, metric_value + margin_of_error)\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1 - alpha) * 100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n\\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n\\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # Calculate standard error of the mean\\n            sem = np.std(results) / np.sqrt(len(results))\\n\\n            # Calculate confidence interval manually\\n            margin_of_error = t.ppf(1 - alpha / 2, len(results) - 1) * sem\\n            confidence_interval = (metric_value - margin_of_error, metric_value + margin_of_error)\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1 - alpha) * 100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  'sem = np.std(results) / np.sqrt(len(results))',\n",
       "  'sem ',\n",
       "  \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n\\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n\\n    metrics = ['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score']\\n    \\n    for metric_name in metrics:\\n        metric_value = locals()[metric_name.lower()]  # Access the metric value dynamically\\n\\n        for alpha in alpha_values:\\n            # Calculate standard error of the mean\\n            sem = np.std(results) / np.sqrt(len(results))\\n\\n            # Calculate t-statistic for the given alpha\\n            t_value = t.ppf(1 - alpha / 2, len(results) - 1)\\n\\n            # Calculate lower and upper bounds of the confidence interval\\n            lower_bound = metric_value - t_value * sem\\n            upper_bound = metric_value + t_value * sem\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1 - alpha) * 100],\\n                'Confidence Interval': [upper_bound - lower_bound],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       "  'metrics',\n",
       "  'metricsmetric_name.lower(',\n",
       "  'metricsmetric_name.lower',\n",
       "  'metricsmetric_name.lower',\n",
       "  'locals()'],\n",
       " 'Out': {19:       Model    Metric     Value  Alpha  \\\n",
       "  0   Model 1  Accuracy  0.696581  0.200   \n",
       "  0   Model 1  Accuracy  0.696581  0.150   \n",
       "  0   Model 1  Accuracy  0.696581  0.100   \n",
       "  0   Model 1  Accuracy  0.696581  0.050   \n",
       "  0   Model 1  Accuracy  0.696581  0.025   \n",
       "  ..      ...       ...       ...    ...   \n",
       "  0   Model 3       AUC  0.754121  0.050   \n",
       "  0   Model 3       AUC  0.754121  0.025   \n",
       "  0   Model 3       AUC  0.754121  0.010   \n",
       "  0   Model 3       AUC  0.754121  0.005   \n",
       "  0   Model 3       AUC  0.754121  0.001   \n",
       "  \n",
       "                           Confidence Interval   p-value  \\\n",
       "  0   (0.6556236315641998, 0.7375387615981933)  0.000083   \n",
       "  0   (0.6505534040262204, 0.7426089891361727)  0.000083   \n",
       "  0   (0.6439525289011624, 0.7492098642612307)  0.000083   \n",
       "  0   (0.6337934763835406, 0.7593689167788525)  0.000083   \n",
       "  0   (0.6246859388785894, 0.7684764542838038)  0.000083   \n",
       "  ..                                       ...       ...   \n",
       "  0    (0.694229839681716, 0.8140119185600424)  0.021846   \n",
       "  0   (0.6855424739645728, 0.8226992842771856)  0.021846   \n",
       "  0   (0.6751731313298386, 0.8330686269119199)  0.021846   \n",
       "  0     (0.66797107582275, 0.8402706824190087)  0.021846   \n",
       "  0   (0.6528096657757041, 0.8554320924660553)  0.021846   \n",
       "  \n",
       "     ANOVA with bonferroni collection p-value DeLong p-value  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  ..                                      ...            ...  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  0                      [0.2424619337408715]            NaN  \n",
       "  \n",
       "  [120 rows x 8 columns],\n",
       "  21: 0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "         ...   \n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  Name: Metric, Length: 120, dtype: object,\n",
       "  23: 0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "         ...   \n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  Name: Metric, Length: 120, dtype: object,\n",
       "  25: 0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "         ...   \n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  Name: Metric, Length: 120, dtype: object,\n",
       "  26: 0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "         ...   \n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  Name: Metric, Length: 120, dtype: object,\n",
       "  27: 0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "  0    Accuracy\n",
       "         ...   \n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  0         AUC\n",
       "  Name: Metric, Length: 120, dtype: object,\n",
       "  49: array([ 0,  3,  4,  7,  8, 11, 17, 34, 36, 39, 40, 42, 45, 47, 48, 50]),\n",
       "  52: array([  0,   3,   6,  11,  13,  14,  15,  16,  17,  19,  32,  35,  36,\n",
       "          38,  39,  41,  46,  48,  57,  60,  68,  69,  73,  74,  75,  79,\n",
       "          80,  81,  82,  86,  96,  99, 102, 105, 108, 109, 111, 112, 113,\n",
       "         115, 117, 121, 124, 133, 138, 141, 143, 145, 148, 156, 160, 169,\n",
       "         171, 177, 180]),\n",
       "  54: array([ 52,  55,  58,  63,  65,  66,  67,  68,  69,  71,  84,  87,  88,\n",
       "          90,  91,  93,  98, 100, 109, 112, 120, 121, 125, 126, 127, 131,\n",
       "         132, 133, 134, 138, 148, 151, 154, 157, 160, 161, 163, 164, 165,\n",
       "         167, 169, 173, 176, 185, 190, 193, 195, 197, 200, 208, 212, 221,\n",
       "         223, 229, 232]),\n",
       "  55: array([160, 173, 190, 154, 223, 134,  65, 100,  84, 126,  88, 109, 138,\n",
       "         176,  67, 121,  98, 157]),\n",
       "  58: array([0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "         1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       "  68: (0.5181467040987666, 0.7282301074954373),\n",
       "  69: 0.6231884057971014,\n",
       "  70: 'F1 Score',\n",
       "  84: 0.031517829165165843,\n",
       "  86: ['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score']},\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7fc6d52a2e80>>,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x7fc6d4231760>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x7fc6d4231760>,\n",
       " 'open': <function io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
       " '_': 0.05,\n",
       " '__': '',\n",
       " '___': '',\n",
       " '__vsc_ipynb_file__': '/home/gil/gcubme_ai2/Workspace/YS_Lee/gcu_pathlogy/code/HistopathologyMMRstatusClassification/anova_with_bonferroni_collection.ipynb',\n",
       " '_i': 'metricsmetric_name.lower',\n",
       " '_ii': ' metricsmetric_name.lower',\n",
       " '_iii': ' metricsmetric_name.lower(',\n",
       " '_i1': 'import numpy as np \\nimport pandas as pd \\nfrom glob import glob\\nfrom scipy import stats\\nfrom sklearn.metrics import confusion_matrix, classification_report\\nfrom scipy.stats import ttest_ind',\n",
       " 'np': <module 'numpy' from '/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/numpy/__init__.py'>,\n",
       " 'pd': <module 'pandas' from '/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/pandas/__init__.py'>,\n",
       " 'glob': <function glob.glob(pathname, *, recursive=False)>,\n",
       " 'stats': <module 'scipy.stats' from '/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/scipy/stats/__init__.py'>,\n",
       " 'confusion_matrix': <function sklearn.metrics._classification.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)>,\n",
       " 'classification_report': <function sklearn.metrics._classification.classification_report(y_true, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')>,\n",
       " 'ttest_ind': <function scipy.stats._stats_py.ttest_ind(a, b, axis=0, equal_var=True, nan_policy='propagate', permutations=None, random_state=None, alternative='two-sided', trim=0, *, keepdims=False)>,\n",
       " '_i2': 'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\ninceptionResNetV2_pred[:inceptionResNetV2_cm[0,0]]=1\\ninceptionResNetV2_pred[52:52+inceptionResNetV2_cm[1,0]]=1\\nefficientNetB2_pred=np.zeros([len(y_test)])\\nefficientNetB2_pred[:efficientNetB2_cm[0,0]]=1\\nefficientNetB2_pred[52:52+efficientNetB2_cm[1,0]]=1\\nefficientNetB3_pred=np.zeros([len(y_test)])\\nefficientNetB3_pred[:efficientNetB3_cm[0,0]]=1\\nefficientNetB3_pred[52:52+efficientNetB3_cm[1,0]]=1',\n",
       " 'inceptionResNetV2_cm': array([[ 36,  16],\n",
       "        [ 55, 127]]),\n",
       " 'efficientNetB2_cm': array([[ 43,   9],\n",
       "        [ 43, 139]]),\n",
       " 'efficientNetB3_cm': array([[ 37,  15],\n",
       "        [ 37, 145]]),\n",
       " 'y_test': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'inceptionResNetV2_pred': array([1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'efficientNetB2_pred': array([1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'efficientNetB3_pred': array([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " '_i3': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['Model 1', 'Model 2', 'Model 3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " 't': <scipy.stats._continuous_distns.t_gen at 0x7fc55e5f5130>,\n",
       " 'f_oneway': <function scipy.stats._stats_py.f_oneway(*samples, axis=0)>,\n",
       " 'multipletests': <function statsmodels.stats.multitest.multipletests(pvals, alpha=0.05, method='hs', maxiter=1, is_sorted=False, returnsorted=False)>,\n",
       " 'accuracy_score': <function sklearn.metrics._classification.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)>,\n",
       " 'precision_score': <function sklearn.metrics._classification.precision_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>,\n",
       " 'recall_score': <function sklearn.metrics._classification.recall_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>,\n",
       " 'f1_score': <function sklearn.metrics._classification.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>,\n",
       " 'data_model1': array([1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'data_model2': array([1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'data_model3': array([1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'results_model1': array([ True,  True, False,  True, False,  True, False,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True, False, False,  True, False,  True,  True,  True,  True,\n",
       "        False,  True,  True, False, False, False,  True,  True,  True,\n",
       "        False,  True, False,  True,  True,  True, False, False, False,\n",
       "        False, False, False, False,  True, False, False,  True, False,\n",
       "        False,  True, False, False, False, False,  True,  True,  True,\n",
       "        False, False, False,  True, False, False,  True,  True, False,\n",
       "        False, False, False,  True, False,  True, False, False,  True,\n",
       "        False, False, False, False, False, False,  True,  True,  True,\n",
       "         True,  True, False, False, False, False,  True, False, False,\n",
       "        False, False,  True, False,  True, False, False, False, False,\n",
       "        False, False, False, False,  True,  True, False,  True, False,\n",
       "        False,  True, False,  True, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False,  True,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False, False,  True, False, False, False,\n",
       "        False,  True, False, False, False,  True, False, False, False,\n",
       "         True,  True,  True, False, False, False, False, False,  True,\n",
       "         True, False, False, False, False, False, False,  True, False,\n",
       "        False, False,  True,  True, False, False,  True, False, False,\n",
       "        False,  True,  True, False, False, False, False,  True, False,\n",
       "        False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True,  True, False,  True, False, False, False, False]),\n",
       " 'results_model2': array([ True,  True, False,  True, False,  True, False,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True, False, False,  True, False,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True, False, False,  True,  True,  True,\n",
       "        False,  True, False,  True,  True,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False,  True, False,  True,\n",
       "        False, False, False,  True, False, False,  True,  True, False,\n",
       "        False, False, False,  True, False,  True, False, False,  True,\n",
       "        False, False, False, False, False, False,  True,  True, False,\n",
       "        False,  True, False, False, False, False,  True, False, False,\n",
       "        False, False, False, False,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False,  True, False,  True, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False,  True,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False, False, False,  True, False,  True, False,  True,\n",
       "        False, False, False, False, False,  True, False, False, False,\n",
       "        False, False, False, False, False,  True, False, False, False,\n",
       "        False,  True,  True, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False,  True, False, False,  True, False, False,\n",
       "        False,  True,  True, False, False, False, False,  True, False,\n",
       "        False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False,  True, False, False, False, False]),\n",
       " 'results_model3': array([ True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False, False, False,  True, False, False,  True, False,\n",
       "        False, False, False, False, False, False,  True,  True,  True,\n",
       "        False, False, False, False, False, False, False,  True, False,\n",
       "        False, False, False,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False,  True,  True,  True,\n",
       "         True,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True, False, False, False, False,\n",
       "        False, False, False, False,  True,  True, False,  True, False,\n",
       "        False,  True, False,  True, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False,  True,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False, False,  True, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False, False,\n",
       "        False,  True,  True, False, False, False, False, False,  True,\n",
       "         True, False, False, False, False, False, False,  True, False,\n",
       "        False, False, False,  True, False, False,  True, False, False,\n",
       "        False, False, False, False, False, False, False,  True, False,\n",
       "        False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True,  True, False,  True, False, False, False, False]),\n",
       " 'true_labels': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'calculate_performance_metrics': <function __main__.calculate_performance_metrics(y_true, y_pred)>,\n",
       " 'alpha_values': [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001],\n",
       " 'result_df':                Model       Metric     Value  Alpha  Confidence Interval  \\\n",
       " 0  inceptionResNetV2     Accuracy  0.696581   80.0             0.081915   \n",
       " 0  inceptionResNetV2     Accuracy  0.696581   85.0             0.092056   \n",
       " 0  inceptionResNetV2     Accuracy  0.696581   90.0             0.105257   \n",
       " 0  inceptionResNetV2     Accuracy  0.696581   95.0             0.125575   \n",
       " 0  inceptionResNetV2     Accuracy  0.696581   97.5             0.143791   \n",
       " 0  inceptionResNetV2     Accuracy  0.696581   99.0             0.165532   \n",
       " 0  inceptionResNetV2     Accuracy  0.696581   99.5             0.180633   \n",
       " 0  inceptionResNetV2     Accuracy  0.696581   99.9             0.212422   \n",
       " 0  inceptionResNetV2  Sensitivity  0.692308   80.0             0.081915   \n",
       " 0  inceptionResNetV2  Sensitivity  0.692308   85.0             0.092056   \n",
       " 0  inceptionResNetV2  Sensitivity  0.692308   90.0             0.105257   \n",
       " 0  inceptionResNetV2  Sensitivity  0.692308   95.0             0.125575   \n",
       " 0  inceptionResNetV2  Sensitivity  0.692308   97.5             0.143791   \n",
       " 0  inceptionResNetV2  Sensitivity  0.692308   99.0             0.165532   \n",
       " 0  inceptionResNetV2  Sensitivity  0.692308   99.5             0.180633   \n",
       " 0  inceptionResNetV2  Sensitivity  0.692308   99.9             0.212422   \n",
       " 0  inceptionResNetV2  Specificity  0.697802   80.0             0.081915   \n",
       " 0  inceptionResNetV2  Specificity  0.697802   85.0             0.092056   \n",
       " 0  inceptionResNetV2  Specificity  0.697802   90.0             0.105257   \n",
       " 0  inceptionResNetV2  Specificity  0.697802   95.0             0.125575   \n",
       " 0  inceptionResNetV2  Specificity  0.697802   97.5             0.143791   \n",
       " 0  inceptionResNetV2  Specificity  0.697802   99.0             0.165532   \n",
       " 0  inceptionResNetV2  Specificity  0.697802   99.5             0.180633   \n",
       " 0  inceptionResNetV2  Specificity  0.697802   99.9             0.212422   \n",
       " \n",
       "     p-value  ANOVA with bonferroni collection p-value  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  \n",
       " 0  0.000083                                  0.242462  ,\n",
       " 'model': 'inceptionResNetV2',\n",
       " 'results': array([ True,  True, False,  True, False,  True, False,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True, False, False,  True, False,  True,  True,  True,  True,\n",
       "        False,  True,  True, False, False, False,  True,  True,  True,\n",
       "        False,  True, False,  True,  True,  True, False, False, False,\n",
       "        False, False, False, False,  True, False, False,  True, False,\n",
       "        False,  True, False, False, False, False,  True,  True,  True,\n",
       "        False, False, False,  True, False, False,  True,  True, False,\n",
       "        False, False, False,  True, False,  True, False, False,  True,\n",
       "        False, False, False, False, False, False,  True,  True,  True,\n",
       "         True,  True, False, False, False, False,  True, False, False,\n",
       "        False, False,  True, False,  True, False, False, False, False,\n",
       "        False, False, False, False,  True,  True, False,  True, False,\n",
       "        False,  True, False,  True, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False,  True,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "         True, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False, False,  True, False, False, False,\n",
       "        False,  True, False, False, False,  True, False, False, False,\n",
       "         True,  True,  True, False, False, False, False, False,  True,\n",
       "         True, False, False, False, False, False, False,  True, False,\n",
       "        False, False,  True,  True, False, False,  True, False, False,\n",
       "        False,  True,  True, False, False, False, False,  True, False,\n",
       "        False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True,  True, False,  True, False, False, False, False]),\n",
       " 'accuracy': 0.6965811965811965,\n",
       " 'sensitivity': 0.6923076923076923,\n",
       " 'specificity': 0.6978021978021978,\n",
       " 'f1': 0.5034965034965035,\n",
       " 't_statistic': 3.9707577731754276,\n",
       " 'p_value_ttest': 8.296618621988492e-05,\n",
       " 'p_value_anova': 0.2424619337408715,\n",
       " 'p_value_anova_corrected': array([0.24246193]),\n",
       " 'metric_name': 'F1 Score',\n",
       " 'metric_value': 0.6978021978021978,\n",
       " 'alpha': 0.001,\n",
       " 'df': 233,\n",
       " 'confidence_interval': (0.5181467040987656, 0.7282301074954373),\n",
       " '_i4': \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\\n\\n# Define the DeLong method\\ndef delong_roc_test(y_true, y_scores1, y_scores2, alpha=0.05):\\n    from pyCM import DeLong\\n    result = DeLong(y_true, y_scores1, y_scores2)\\n    return result.p_value, result.variance\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'DeLong p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # DeLong method\\n            auc_diff, auc_var = delong_roc_test(true_labels, results_prob, results_model1, alpha=0.05)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'DeLong p-value': [auc_diff]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " 'roc_auc_score': <function sklearn.metrics._ranking.roc_auc_score(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)>,\n",
       " 'roc_curve': <function sklearn.metrics._ranking.roc_curve(y_true, y_score, *, pos_label=None, sample_weight=None, drop_intermediate=True)>,\n",
       " 'delong_roc_test': <function __main__.delong_roc_test(y_true, y_scores1, y_scores2)>,\n",
       " 'results_prob': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'fpr': array([0.       , 0.3021978, 1.       ]),\n",
       " 'tpr': array([0.        , 0.69230769, 1.        ]),\n",
       " '_i5': \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\\n# Define the DeLong method\\ndef delong_roc_test(y_true, y_scores1, y_scores2, alpha=0.05):\\n    from pycm import DeLong\\n    result = DeLong(y_true, y_scores1, y_scores2)\\n    return result.p_value, result.variance\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'DeLong p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # DeLong method\\n            auc_diff, auc_var = delong_roc_test(true_labels, results_prob, results_model1, alpha=0.05)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'DeLong p-value': [auc_diff]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i6': \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\\n# Define the DeLong method\\ndef delong_roc_test(y_true, y_scores1, y_scores2, alpha=0.05):\\n    from pyCM import DeLong\\n    result = DeLong(y_true, y_scores1, y_scores2)\\n    return result.p_value, result.variance\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'DeLong p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # DeLong method\\n            auc_diff, auc_var = delong_roc_test(true_labels, results_prob, results_model1, alpha=0.05)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'DeLong p-value': [auc_diff]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i7': \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import (\\n    accuracy_score, precision_score, recall_score, f1_score,\\n    confusion_matrix, roc_auc_score, roc_curve\\n)\\nfrom mlxtend.evaluate import delong_test\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred_prob  # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred_prob\\ndata_model3 = efficientNetB3_pred_prob\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'DeLong p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # DeLong method\\n            auc_diff, auc_var, p_value_delong = delong_test(true_labels, results_prob, results_model1)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'DeLong p-value': [p_value_delong]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i8': 'from pycm import DeLong',\n",
       " '_i9': 'from pycm import delong_test',\n",
       " '_i10': 'from pycm import delong',\n",
       " '_i11': 'from pycm import DeLong',\n",
       " '_i12': \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, wilcoxon\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import (\\n    accuracy_score, precision_score, recall_score, f1_score,\\n    confusion_matrix, roc_auc_score, roc_curve\\n)\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred_prob  # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred_prob\\ndata_model3 = efficientNetB3_pred_prob\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'Wilcoxon p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # Wilcoxon signed-rank test\\n            _, p_value_wilcoxon = wilcoxon(results_prob, results_model1)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'Wilcoxon p-value': [p_value_wilcoxon]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " 'wilcoxon': <function scipy.stats._morestats.wilcoxon(x, y=None, zero_method='wilcox', correction=False, alternative='two-sided', method='auto', *, axis=0, nan_policy='propagate', keepdims=False)>,\n",
       " '_i13': \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, wilcoxon\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import (\\n    accuracy_score, precision_score, recall_score, f1_score,\\n    confusion_matrix, roc_auc_score, roc_curve\\n)\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred  # Use probability scores instead of binary predictions\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0.5\\nresults_model2 = data_model2 > 0.5\\nresults_model3 = data_model3 > 0.5\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value', 'Wilcoxon p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results_prob, results in zip(['Model 1', 'Model 2', 'Model 3'], [data_model1, data_model2, data_model3], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # Calculate ROC curve\\n            fpr, tpr, _ = roc_curve(true_labels, results_prob)\\n            \\n            # Wilcoxon signed-rank test\\n            _, p_value_wilcoxon = wilcoxon(results_prob, results_model1)\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected],\\n                'Wilcoxon p-value': [p_value_wilcoxon]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i14': 'p_value_wilcoxon ',\n",
       " '_i15': 'p_value_wilcoxon',\n",
       " '_i16': 'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\n\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 DataFrame에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                \\'Model\\': [model],\\n                \\'Metric\\': [metric_name],\\n                \\'Value\\': [metric_value],\\n                \\'Alpha\\': [alpha],\\n                \\'Confidence Interval\\': [confidence_interval],\\n                \\'p-value\\': [p_value_ttest],\\n                \\'ANOVA with bonferroni collection p-value\\': [p_value_anova_corrected],\\n                \\'DeLong p-value\\': [np.nan]  # Placeholder for DeLong p-value\\n            })])\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_df)):\\n    for j in range(i + 1, len(result_df)):\\n        if result_df.at[i, \\'Metric\\'] == result_df.at[j, \\'Metric\\'] and result_df.at[i, \\'Alpha\\'] == result_df.at[j, \\'Alpha\\']:\\n            metric_name = result_df.at[i, \\'Metric\\']\\n            alpha = result_df.at[i, \\'Alpha\\']\\n            model1 = result_df.at[i, \\'Model\\']\\n            model2 = result_df.at[j, \\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_df.at[i, \\'DeLong p-value\\'] = delong_p_value\\n            result_df.at[j, \\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       " 'auc': <function sklearn.metrics._ranking.auc(x, y)>,\n",
       " 'pairwise_distances': <function sklearn.metrics.pairwise.pairwise_distances(X, Y=None, metric='euclidean', *, n_jobs=None, force_all_finite=True, **kwds)>,\n",
       " 'check_array': <function sklearn.utils.validation.check_array(array, accept_sparse=False, *, accept_large_sparse=True, dtype='numeric', order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, estimator=None, input_name='')>,\n",
       " 'data_model': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'auc_value': 0.7541208791208792,\n",
       " 'i': 119,\n",
       " 'j': 119,\n",
       " '_i17': \" result_df.at[j, 'Metric']\",\n",
       " '_i18': \"result_df.at[j, 'Metric']\",\n",
       " '_i19': 'result_df',\n",
       " '_19':       Model    Metric     Value  Alpha  \\\n",
       " 0   Model 1  Accuracy  0.696581  0.200   \n",
       " 0   Model 1  Accuracy  0.696581  0.150   \n",
       " 0   Model 1  Accuracy  0.696581  0.100   \n",
       " 0   Model 1  Accuracy  0.696581  0.050   \n",
       " 0   Model 1  Accuracy  0.696581  0.025   \n",
       " ..      ...       ...       ...    ...   \n",
       " 0   Model 3       AUC  0.754121  0.050   \n",
       " 0   Model 3       AUC  0.754121  0.025   \n",
       " 0   Model 3       AUC  0.754121  0.010   \n",
       " 0   Model 3       AUC  0.754121  0.005   \n",
       " 0   Model 3       AUC  0.754121  0.001   \n",
       " \n",
       "                          Confidence Interval   p-value  \\\n",
       " 0   (0.6556236315641998, 0.7375387615981933)  0.000083   \n",
       " 0   (0.6505534040262204, 0.7426089891361727)  0.000083   \n",
       " 0   (0.6439525289011624, 0.7492098642612307)  0.000083   \n",
       " 0   (0.6337934763835406, 0.7593689167788525)  0.000083   \n",
       " 0   (0.6246859388785894, 0.7684764542838038)  0.000083   \n",
       " ..                                       ...       ...   \n",
       " 0    (0.694229839681716, 0.8140119185600424)  0.021846   \n",
       " 0   (0.6855424739645728, 0.8226992842771856)  0.021846   \n",
       " 0   (0.6751731313298386, 0.8330686269119199)  0.021846   \n",
       " 0     (0.66797107582275, 0.8402706824190087)  0.021846   \n",
       " 0   (0.6528096657757041, 0.8554320924660553)  0.021846   \n",
       " \n",
       "    ANOVA with bonferroni collection p-value DeLong p-value  \n",
       " 0                      [0.2424619337408715]            NaN  \n",
       " 0                      [0.2424619337408715]            NaN  \n",
       " 0                      [0.2424619337408715]            NaN  \n",
       " 0                      [0.2424619337408715]            NaN  \n",
       " 0                      [0.2424619337408715]            NaN  \n",
       " ..                                      ...            ...  \n",
       " 0                      [0.2424619337408715]            NaN  \n",
       " 0                      [0.2424619337408715]            NaN  \n",
       " 0                      [0.2424619337408715]            NaN  \n",
       " 0                      [0.2424619337408715]            NaN  \n",
       " 0                      [0.2424619337408715]            NaN  \n",
       " \n",
       " [120 rows x 8 columns],\n",
       " '_i20': \"result_df.at[j, 'Metric']\",\n",
       " '_i21': \"result_df.at[0, 'Metric']\",\n",
       " '_21': 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       "        ...   \n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " Name: Metric, Length: 120, dtype: object,\n",
       " '_i22': \"result_df.at[1, 'Metric']\",\n",
       " '_i23': \"result_df.at[0, 'Metric']\",\n",
       " '_23': 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       "        ...   \n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " Name: Metric, Length: 120, dtype: object,\n",
       " '_i24': \"result_df.at[j, 'Metric']\",\n",
       " '_i25': \"result_df.at[i, 'Metric']\",\n",
       " '_25': 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       "        ...   \n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " Name: Metric, Length: 120, dtype: object,\n",
       " '_i26': \"result_df.at[0, 'Metric']\",\n",
       " '_26': 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       "        ...   \n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " Name: Metric, Length: 120, dtype: object,\n",
       " '_i27': \"result_df.loc[0, 'Metric']\",\n",
       " '_27': 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       " 0    Accuracy\n",
       "        ...   \n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " 0         AUC\n",
       " Name: Metric, Length: 120, dtype: object,\n",
       " '_i28': 'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\n\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       " '_i29': 'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\n\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\nresult_list = []\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       " 'result_list': [{'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.6965811965811965,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.6556236315641998, 0.7375387615981933),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.6965811965811965,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.6505534040262204, 0.7426089891361727),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.6965811965811965,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.6439525289011624, 0.7492098642612307),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.6965811965811965,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.6337934763835406, 0.7593689167788525),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.6965811965811965,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.6246859388785894, 0.7684764542838038),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.6965811965811965,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.6138150742203683, 0.7793473189420248),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.6965811965811965,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.6062646852095647, 0.7868977079528287),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.6965811965811965,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.5903699807470911, 0.802792412415303),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.6923076923076923,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.6513501272906955, 0.7332652573246891),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.6923076923076923,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.6462798997527162, 0.7383354848626684),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.6923076923076923,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.6396790246276581, 0.7449363599877264),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.6923076923076923,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.6295199721100363, 0.7550954125053483),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.6923076923076923,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.6204124346050851, 0.7642029500102996),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.6923076923076923,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.609541569946864, 0.7750738146685205),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.6923076923076923,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.6019911809360604, 0.7826242036793244),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.6923076923076923,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.5860964764735869, 0.7985189081417987),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.6978021978021978,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.656844632785201, 0.7387597628191945),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.6978021978021978,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.6517744052472216, 0.7438299903571739),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.6978021978021978,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.6451735301221636, 0.7504308654822319),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.6978021978021978,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.6350144776045418, 0.7605899179998538),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.6978021978021978,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.6259069400995906, 0.7696974555048051),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.6978021978021978,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.6150360754413695, 0.780568320163026),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.6978021978021978,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.6074856864305659, 0.7881187091738299),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.6978021978021978,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.5915909819680923, 0.8040134136363042),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5034965034965035,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.4625389384795068, 0.5444540685135003),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5034965034965035,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.4574687109415274, 0.5495242960514797),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5034965034965035,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.4508678358164694, 0.5561251711765377),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5034965034965035,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.4407087832988476, 0.5662842236941595),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5034965034965035,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.4316012457938963, 0.5753917611991108),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5034965034965035,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.4207303811356753, 0.5862626258573318),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5034965034965035,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.41317999212487166, 0.5938130148681356),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5034965034965035,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.3972852876623981, 0.60970771933061),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.695054945054945,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.6540973800379483, 0.7360125100719418),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.695054945054945,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.6490271524999689, 0.7410827376099212),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.695054945054945,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.6424262773749109, 0.7476836127349792),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.695054945054945,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.632267224857289, 0.757842665252601),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.695054945054945,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.6231596873523378, 0.7669502027575523),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.695054945054945,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.6122888226941168, 0.7778210674157733),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.695054945054945,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.6047384336833131, 0.7853714564265771),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'inceptionResNetV2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.695054945054945,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.5888437292208396, 0.8012661608890514),\n",
       "   'p-value': 8.296618621988492e-05,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.7372712051618937, 0.8182843503936619),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.7322568069704732, 0.8232987485850823),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.7257286154759205, 0.829826940079635),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.7156814264317756, 0.83987412912378),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.7066741739463531, 0.8488813816092026),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.6959230106754667, 0.8596325448800889),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.688455760593159, 0.8670997949623969),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.672736076079443, 0.8828194794761136),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.8269230769230769,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.7864165043071928, 0.867429649538961),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.8269230769230769,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.7814021061157723, 0.8724440477303814),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.8269230769230769,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.7748739146212196, 0.8789722392249341),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.8269230769230769,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.7648267255770747, 0.8890194282690791),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.8269230769230769,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.7558194730916522, 0.8980266807545016),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.8269230769230769,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.7450683098207658, 0.908777844025388),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.8269230769230769,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.7376010597384581, 0.9162450941076958),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.8269230769230769,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.721881375224742, 0.9319647786214127),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7637362637362637,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.7232296911203796, 0.8042428363521478),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7637362637362637,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.7182152929289591, 0.8092572345435682),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7637362637362637,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.7116871014344064, 0.8157854260381209),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7637362637362637,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.7016399123902615, 0.8258326150822659),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7637362637362637,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.692632659904839, 0.8348398675676885),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7637362637362637,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.6818814966339526, 0.8455910308385748),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7637362637362637,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.674414246551645, 0.8530582809208827),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7637362637362637,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.6586945620379289, 0.8687779654345995),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.6231884057971014,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.5826818331812174, 0.6636949784129855),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.6231884057971014,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.5776674349897969, 0.668709376604406),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.6231884057971014,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.5711392434952441, 0.6752375680989586),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.6231884057971014,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.5610920544510992, 0.6852847571431037),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.6231884057971014,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.5520848019656768, 0.6942920096285262),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.6231884057971014,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.5413336386947903, 0.7050431728994125),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.6231884057971014,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.5338663886124827, 0.7125104229817205),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.6231884057971014,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.5181467040987666, 0.7282301074954373),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7953296703296703,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.7548230977137862, 0.8358362429455544),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7953296703296703,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.7498086995223657, 0.8408506411369748),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7953296703296703,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.743280508027813, 0.8473788326315275),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7953296703296703,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.7332333189836681, 0.8574260216756725),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7953296703296703,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.7242260664982456, 0.8664332741610951),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7953296703296703,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.7134749032273592, 0.8771844374319814),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7953296703296703,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.7060076531450515, 0.8846516875142894),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB2',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7953296703296703,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.6902879686313355, 0.9003713720280061),\n",
       "   'p-value': 0.000540935982606621,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.7387097699883085, 0.8168457855672471),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.7338734549176748, 0.8216821006378808),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.7275771079376708, 0.8279784476178847),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.7178867383386146, 0.837668817216941),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.7091993726214714, 0.8463561829340842),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.6988300299867372, 0.8567255255688184),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.6916279744796485, 0.8639275810759073),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Accuracy',\n",
       "   'Value': 0.7777777777777778,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.6764665644326027, 0.8790889911229539),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.7115384615384616,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.6724704537489923, 0.7506064693279308),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.7115384615384616,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.6676341386783585, 0.7554427843985646),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.7115384615384616,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.6613377916983546, 0.7617391313785685),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.7115384615384616,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.6516474220992984, 0.7714295009776247),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.7115384615384616,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.6429600563821551, 0.780116866694768),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.7115384615384616,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.6325907137474209, 0.7904862093295022),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.7115384615384616,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.6253886582403323, 0.797688264836591),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Sensitivity',\n",
       "   'Value': 0.7115384615384616,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.6102272481932864, 0.8128496748836377),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7967032967032966,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.7576352889138274, 0.8357713044927659),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7967032967032966,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.7527989738431936, 0.8406076195633997),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7967032967032966,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.7465026268631897, 0.8469039665434036),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7967032967032966,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.7368122572641335, 0.8565943361424598),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7967032967032966,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.7281248915469902, 0.8652817018596031),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7967032967032966,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.717755548912256, 0.8756510444943373),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7967032967032966,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.7105534934051674, 0.8828531000014261),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'Specificity',\n",
       "   'Value': 0.7967032967032966,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.6953920833581215, 0.8980145100484728),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5873015873015872,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.5482335795121179, 0.6263695950910565),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5873015873015872,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.5433972644414842, 0.6312059101616903),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5873015873015872,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.5371009174614803, 0.6375022571416942),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5873015873015872,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.527410547862424, 0.6471926267407504),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5873015873015872,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.5187231821452809, 0.6558799924578936),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5873015873015872,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.5083538395105466, 0.6662493350926278),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5873015873015872,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.501151784003458, 0.6734513905997167),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'F1 Score',\n",
       "   'Value': 0.5873015873015872,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.4859903739564121, 0.6886128006467633),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7541208791208792,\n",
       "   'Alpha': 0.2,\n",
       "   'Confidence Interval': (0.7150528713314099, 0.7931888869103485),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7541208791208792,\n",
       "   'Alpha': 0.15,\n",
       "   'Confidence Interval': (0.7102165562607762, 0.7980252019809823),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7541208791208792,\n",
       "   'Alpha': 0.1,\n",
       "   'Confidence Interval': (0.7039202092807723, 0.8043215489609862),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7541208791208792,\n",
       "   'Alpha': 0.05,\n",
       "   'Confidence Interval': (0.694229839681716, 0.8140119185600424),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7541208791208792,\n",
       "   'Alpha': 0.025,\n",
       "   'Confidence Interval': (0.6855424739645728, 0.8226992842771856),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7541208791208792,\n",
       "   'Alpha': 0.01,\n",
       "   'Confidence Interval': (0.6751731313298386, 0.8330686269119199),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7541208791208792,\n",
       "   'Alpha': 0.005,\n",
       "   'Confidence Interval': (0.66797107582275, 0.8402706824190087),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan},\n",
       "  {'Model': 'efficientNetB3',\n",
       "   'Metric': 'AUC',\n",
       "   'Value': 0.7541208791208792,\n",
       "   'Alpha': 0.001,\n",
       "   'Confidence Interval': (0.6528096657757041, 0.8554320924660553),\n",
       "   'p-value': 0.02184626959009473,\n",
       "   'ANOVA with bonferroni collection p-value': array([0.24246193]),\n",
       "   'DeLong p-value': nan}],\n",
       " 'model1': 'efficientNetB2',\n",
       " 'model2': 'efficientNetB3',\n",
       " 'y_scores1': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'y_scores2': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " '_i30': 'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\nrom scipy.stats import norm\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\nresult_list = []\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       " '_i31': 'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\nfrom scipy.stats import norm\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\nresult_list = []\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'Model 1\\', \\'Model 2\\', \\'Model 3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       " 'norm': <scipy.stats._continuous_distns.norm_gen at 0x7fc55e6f86d0>,\n",
       " 'delong_p_value': nan,\n",
       " '_i32': 'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\\nfrom sklearn.metrics import roc_curve, auc\\nfrom sklearn.metrics import pairwise_distances\\nfrom sklearn.utils import check_array\\nfrom scipy.stats import norm\\n# DeLong method for comparing ROC curves\\ndef delong_roc_test(y_true, y_scores1, y_scores2):\\n    fpr1, tpr1, _ = roc_curve(y_true, y_scores1)\\n    fpr2, tpr2, _ = roc_curve(y_true, y_scores2)\\n\\n    auc1 = auc(fpr1, tpr1)\\n    auc2 = auc(fpr2, tpr2)\\n    roc_distances = pairwise_distances(\\n        y_true.reshape(-1, 1), y_scores1.reshape(-1, 1), metric=\"manhattan\"\\n    ) - pairwise_distances(y_true.reshape(-1, 1), y_scores2.reshape(-1, 1), metric=\"manhattan\")\\n\\n    delong_variance = np.var(roc_distances, ddof=2) / 4.0\\n\\n    delong_se = np.sqrt(delong_variance)\\n\\n    z_score = (auc1 - auc2) / delong_se\\n\\n    p_value = 2 * (1.0 - norm.cdf(np.abs(z_score)))\\n\\n    return z_score, p_value\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\nresult_list = []\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, y_scores):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    auc_value = roc_auc_score(y_true, y_scores)\\n    return accuracy, sensitivity, specificity, f1, auc_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\', \\'DeLong p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value, DeLong p-value 계산 및 리스트에 저장\\nfor model, results, data_model in zip([\\'inceptionResNetV2\\', \\'efficientNetB2\\', \\'efficientNetB3\\'], [results_model1, results_model2, results_model3], [data_model1, data_model2, data_model3]):\\n    accuracy, sensitivity, specificity, f1, auc_value = calculate_performance_metrics(true_labels, results, data_model)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n    \\n    for metric_name, metric_value in zip([\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\', \\'AUC\\'], [accuracy, sensitivity, specificity, f1, auc_value]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 리스트에 추가\\n            result_list.append({\\n                \\'Model\\': model,\\n                \\'Metric\\': metric_name,\\n                \\'Value\\': metric_value,\\n                \\'Alpha\\': alpha,\\n                \\'Confidence Interval\\': confidence_interval,\\n                \\'p-value\\': p_value_ttest,\\n                \\'ANOVA with bonferroni collection p-value\\': p_value_anova_corrected,\\n                \\'DeLong p-value\\': np.nan  # Placeholder for DeLong p-value\\n            })\\n\\n# Calculate DeLong p-value for pairwise comparisons\\nfor i in range(len(result_list)):\\n    for j in range(i + 1, len(result_list)):\\n        if result_list[i][\\'Metric\\'] == result_list[j][\\'Metric\\'] and result_list[i][\\'Alpha\\'] == result_list[j][\\'Alpha\\']:\\n            metric_name = result_list[i][\\'Metric\\']\\n            alpha = result_list[i][\\'Alpha\\']\\n            model1 = result_list[i][\\'Model\\']\\n            model2 = result_list[j][\\'Model\\']\\n            y_scores1 = data_model1 if model1 == \\'Model 1\\' else (data_model2 if model1 == \\'Model 2\\' else data_model3)\\n            y_scores2 = data_model1 if model2 == \\'Model 1\\' else (data_model2 if model2 == \\'Model 2\\' else data_model3)\\n            _, delong_p_value = delong_roc_test(true_labels, y_scores1, y_scores2)\\n            result_list[i][\\'DeLong p-value\\'] = delong_p_value\\n            result_list[j][\\'DeLong p-value\\'] = delong_p_value\\n\\n# 결과 리스트로부터 DataFrame 생성\\nresult_df = pd.DataFrame(result_list)\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       " '_i33': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i34': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [confidence_interval],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i35': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': '±'+str(metric_value-confidence_interval[0]),\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i36': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': '±'+str(metric_value-confidence_interval[0]),\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv',encoding='cp949', index=False)\",\n",
       " '_i37': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i38': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i39': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[alpha],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i40': \"import pandas as pd\\n\\n# CSV 파일에서 데이터 읽기\\ncsv_file = 'model_comparison_results.csv'\\ndf = pd.read_csv(csv_file)\\n\\n# 데이터를 원하는 형식으로 가공\\ntable = df.pivot_table(index=['Model', 'Metric'], columns='Alpha', values=['Value', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 워드 논문 형식에 맞게 컬럼 정렬\\ntable = table[[('Value', 0.2), ('Value', 0.15), ('Value', 0.1), ('Value', 0.05), ('Value', 0.025), ('Value', 0.01), ('Value', 0.005), ('Value', 0.001),\\n               ('Confidence Interval', 0.2), ('Confidence Interval', 0.15), ('Confidence Interval', 0.1), ('Confidence Interval', 0.05), ('Confidence Interval', 0.025), ('Confidence Interval', 0.01), ('Confidence Interval', 0.005), ('Confidence Interval', 0.001),\\n               ('p-value', 0.2), ('p-value', 0.15), ('p-value', 0.1), ('p-value', 0.05), ('p-value', 0.025), ('p-value', 0.01), ('p-value', 0.005), ('p-value', 0.001),\\n               ('ANOVA with bonferroni collection p-value', 0.2), ('ANOVA with bonferroni collection p-value', 0.15), ('ANOVA with bonferroni collection p-value', 0.1), ('ANOVA with bonferroni collection p-value', 0.05), ('ANOVA with bonferroni collection p-value', 0.025), ('ANOVA with bonferroni collection p-value', 0.01), ('ANOVA with bonferroni collection p-value', 0.005), ('ANOVA with bonferroni collection p-value', 0.001)]]\\n\\n# 워드 표 형식으로 출력\\nprint(table.to_markdown())\",\n",
       " 'csv_file': 'model_comparison_results.csv',\n",
       " 'table':                                   Value Confidence Interval            \\\n",
       " Alpha                             0.200               0.200     0.150   \n",
       " Model             Metric                                                \n",
       " efficientNetB2    Accuracy     0.777778            0.040507  0.045521   \n",
       "                   F1 Score     0.623188            0.040507  0.045521   \n",
       "                   Sensitivity  0.826923            0.040507  0.045521   \n",
       "                   Specificity  0.763736            0.040507  0.045521   \n",
       " efficientNetB3    Accuracy     0.777778            0.039068  0.043904   \n",
       "                   F1 Score     0.587302            0.039068  0.043904   \n",
       "                   Sensitivity  0.711538            0.039068  0.043904   \n",
       "                   Specificity  0.796703            0.039068  0.043904   \n",
       " inceptionResNetV2 Accuracy     0.696581            0.040958  0.046028   \n",
       "                   F1 Score     0.503497            0.040958  0.046028   \n",
       "                   Sensitivity  0.692308            0.040958  0.046028   \n",
       "                   Specificity  0.697802            0.040958  0.046028   \n",
       " \n",
       "                                                                        \\\n",
       " Alpha                             0.100     0.050     0.025     0.010   \n",
       " Model             Metric                                                \n",
       " efficientNetB2    Accuracy     0.052049  0.062096  0.071104  0.081855   \n",
       "                   F1 Score     0.052049  0.062096  0.071104  0.081855   \n",
       "                   Sensitivity  0.052049  0.062096  0.071104  0.081855   \n",
       "                   Specificity  0.052049  0.062096  0.071104  0.081855   \n",
       " efficientNetB3    Accuracy     0.050201  0.059891  0.068578  0.078948   \n",
       "                   F1 Score     0.050201  0.059891  0.068578  0.078948   \n",
       "                   Sensitivity  0.050201  0.059891  0.068578  0.078948   \n",
       "                   Specificity  0.050201  0.059891  0.068578  0.078948   \n",
       " inceptionResNetV2 Accuracy     0.052629  0.062788  0.071895  0.082766   \n",
       "                   F1 Score     0.052629  0.062788  0.071895  0.082766   \n",
       "                   Sensitivity  0.052629  0.062788  0.071895  0.082766   \n",
       "                   Specificity  0.052629  0.062788  0.071895  0.082766   \n",
       " \n",
       "                                                     p-value  \\\n",
       " Alpha                             0.005     0.001     0.200   \n",
       " Model             Metric                                      \n",
       " efficientNetB2    Accuracy     0.089322  0.105042  0.000541   \n",
       "                   F1 Score     0.089322  0.105042  0.000541   \n",
       "                   Sensitivity  0.089322  0.105042  0.000541   \n",
       "                   Specificity  0.089322  0.105042  0.000541   \n",
       " efficientNetB3    Accuracy     0.086150  0.101311  0.021846   \n",
       "                   F1 Score     0.086150  0.101311  0.021846   \n",
       "                   Sensitivity  0.086150  0.101311  0.021846   \n",
       "                   Specificity  0.086150  0.101311  0.021846   \n",
       " inceptionResNetV2 Accuracy     0.090317  0.106211  0.000083   \n",
       "                   F1 Score     0.090317  0.106211  0.000083   \n",
       "                   Sensitivity  0.090317  0.106211  0.000083   \n",
       "                   Specificity  0.090317  0.106211  0.000083   \n",
       " \n",
       "                               ANOVA with bonferroni collection p-value  \\\n",
       " Alpha                                                            0.200   \n",
       " Model             Metric                                                 \n",
       " efficientNetB2    Accuracy                                    0.242462   \n",
       "                   F1 Score                                    0.242462   \n",
       "                   Sensitivity                                 0.242462   \n",
       "                   Specificity                                 0.242462   \n",
       " efficientNetB3    Accuracy                                    0.242462   \n",
       "                   F1 Score                                    0.242462   \n",
       "                   Sensitivity                                 0.242462   \n",
       "                   Specificity                                 0.242462   \n",
       " inceptionResNetV2 Accuracy                                    0.242462   \n",
       "                   F1 Score                                    0.242462   \n",
       "                   Sensitivity                                 0.242462   \n",
       "                   Specificity                                 0.242462   \n",
       " \n",
       "                                                                        \\\n",
       " Alpha                             0.150     0.100     0.050     0.025   \n",
       " Model             Metric                                                \n",
       " efficientNetB2    Accuracy     0.242462  0.242462  0.242462  0.242462   \n",
       "                   F1 Score     0.242462  0.242462  0.242462  0.242462   \n",
       "                   Sensitivity  0.242462  0.242462  0.242462  0.242462   \n",
       "                   Specificity  0.242462  0.242462  0.242462  0.242462   \n",
       " efficientNetB3    Accuracy     0.242462  0.242462  0.242462  0.242462   \n",
       "                   F1 Score     0.242462  0.242462  0.242462  0.242462   \n",
       "                   Sensitivity  0.242462  0.242462  0.242462  0.242462   \n",
       "                   Specificity  0.242462  0.242462  0.242462  0.242462   \n",
       " inceptionResNetV2 Accuracy     0.242462  0.242462  0.242462  0.242462   \n",
       "                   F1 Score     0.242462  0.242462  0.242462  0.242462   \n",
       "                   Sensitivity  0.242462  0.242462  0.242462  0.242462   \n",
       "                   Specificity  0.242462  0.242462  0.242462  0.242462   \n",
       " \n",
       "                                                              \n",
       " Alpha                             0.010     0.005     0.001  \n",
       " Model             Metric                                     \n",
       " efficientNetB2    Accuracy     0.242462  0.242462  0.242462  \n",
       "                   F1 Score     0.242462  0.242462  0.242462  \n",
       "                   Sensitivity  0.242462  0.242462  0.242462  \n",
       "                   Specificity  0.242462  0.242462  0.242462  \n",
       " efficientNetB3    Accuracy     0.242462  0.242462  0.242462  \n",
       "                   F1 Score     0.242462  0.242462  0.242462  \n",
       "                   Sensitivity  0.242462  0.242462  0.242462  \n",
       "                   Specificity  0.242462  0.242462  0.242462  \n",
       " inceptionResNetV2 Accuracy     0.242462  0.242462  0.242462  \n",
       "                   F1 Score     0.242462  0.242462  0.242462  \n",
       "                   Sensitivity  0.242462  0.242462  0.242462  \n",
       "                   Specificity  0.242462  0.242462  0.242462  ,\n",
       " '_i41': \"import pandas as pd\\n\\n# CSV 파일에서 데이터 읽기\\ncsv_file = 'model_comparison_results.csv'\\ndf = pd.read_csv(csv_file)\\n\\n# 데이터를 원하는 형식으로 가공\\ntable = df.pivot_table(index=['Model', 'Metric'], columns='Alpha', values=['Value', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 워드 논문 형식에 맞게 컬럼 정렬\\ntable = table[[('Value'),\\n               ('Confidence Interval', 0.2), ('Confidence Interval', 0.15), ('Confidence Interval', 0.1), ('Confidence Interval', 0.05), ('Confidence Interval', 0.025), ('Confidence Interval', 0.01), ('Confidence Interval', 0.005), ('Confidence Interval', 0.001),\\n               ('p-value', 0.2), ('p-value', 0.15), ('p-value', 0.1), ('p-value', 0.05), ('p-value', 0.025), ('p-value', 0.01), ('p-value', 0.005), ('p-value', 0.001),\\n               ('ANOVA with bonferroni collection p-value', 0.2), ('ANOVA with bonferroni collection p-value', 0.15), ('ANOVA with bonferroni collection p-value', 0.1), ('ANOVA with bonferroni collection p-value', 0.05), ('ANOVA with bonferroni collection p-value', 0.025), ('ANOVA with bonferroni collection p-value', 0.01), ('ANOVA with bonferroni collection p-value', 0.005), ('ANOVA with bonferroni collection p-value', 0.001)]]\\n\\n# 워드 표 형식으로 출력\\nprint(table.to_markdown())\",\n",
       " '_i42': \"import pandas as pd\\n\\n# CSV 파일에서 데이터 읽기\\ncsv_file = 'model_comparison_results.csv'\\ndf = pd.read_csv(csv_file)\\n\\n# 데이터를 원하는 형식으로 가공\\ntable = df.pivot_table(index=['Model', 'Metric'], columns='Alpha', values=['Value', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 워드 논문 형식에 맞게 컬럼 정렬\\ntable = table[[('Value', 0.2),\\n               ('Confidence Interval', 0.2), ('Confidence Interval', 0.15), ('Confidence Interval', 0.1), ('Confidence Interval', 0.05), ('Confidence Interval', 0.025), ('Confidence Interval', 0.01), ('Confidence Interval', 0.005), ('Confidence Interval', 0.001),\\n               ('p-value', 0.2), ('p-value', 0.15), ('p-value', 0.1), ('p-value', 0.05), ('p-value', 0.025), ('p-value', 0.01), ('p-value', 0.005), ('p-value', 0.001),\\n               ('ANOVA with bonferroni collection p-value', 0.2), ('ANOVA with bonferroni collection p-value', 0.15), ('ANOVA with bonferroni collection p-value', 0.1), ('ANOVA with bonferroni collection p-value', 0.05), ('ANOVA with bonferroni collection p-value', 0.025), ('ANOVA with bonferroni collection p-value', 0.01), ('ANOVA with bonferroni collection p-value', 0.005), ('ANOVA with bonferroni collection p-value', 0.001)]]\\n\\n# 워드 표 형식으로 출력\\nprint(table.to_markdown())\",\n",
       " '_i43': \"import pandas as pd\\n\\n# CSV 파일에서 데이터 읽기\\ncsv_file = 'model_comparison_results.csv'\\ndf = pd.read_csv(csv_file)\\n\\n# 데이터를 원하는 형식으로 가공\\ntable = df.pivot_table(index=['Model', 'Metric'], columns='Alpha', values=['Value', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 워드 논문 형식에 맞게 컬럼 정렬\\ntable = table[[('Value', 0.2),\\n               ('Confidence Interval', 0.2), ('Confidence Interval', 0.15), ('Confidence Interval', 0.1), ('Confidence Interval', 0.05), ('Confidence Interval', 0.025), ('Confidence Interval', 0.01), ('Confidence Interval', 0.005), ('Confidence Interval', 0.001),\\n               ('p-value', 0.2),\\n               ('ANOVA with bonferroni collection p-value', 0.2), ('ANOVA with bonferroni collection p-value', 0.15), ('ANOVA with bonferroni collection p-value', 0.1), ('ANOVA with bonferroni collection p-value', 0.05), ('ANOVA with bonferroni collection p-value', 0.025), ('ANOVA with bonferroni collection p-value', 0.01), ('ANOVA with bonferroni collection p-value', 0.005), ('ANOVA with bonferroni collection p-value', 0.001)]]\\n\\n# 워드 표 형식으로 출력\\nprint(table.to_markdown())\",\n",
       " '_i44': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i45': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i46': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False) \",\n",
       " '_i47': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False) \",\n",
       " '_i48': 'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=inceptionResNetV2_pred',\n",
       " 'numbers': array([ 7, 35,  2, 46, 17, 10, 18,  6, 45, 42, 11, 36]),\n",
       " '_i49': 'np.where(efficientNetB2_pred[:52]==0)[0]',\n",
       " '_49': array([ 0,  3,  4,  7,  8, 11, 17, 34, 36, 39, 40, 42, 45, 47, 48, 50]),\n",
       " '_i50': 'efficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)',\n",
       " '_i51': 'ffp=np.where(efficientNetB2_pred[52:]==1)[0]\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)',\n",
       " 'ffp': array([ 58,  61,  64,  69,  70,  71,  75,  78,  79,  84,  86,  89,  96,\n",
       "         97,  98,  99, 100, 105, 110, 112, 121, 122, 124, 127, 129, 136,\n",
       "        143, 153, 155, 157, 159, 161, 163, 167, 172, 176, 180, 181, 182,\n",
       "        188, 189, 196, 200, 201, 204, 208, 209, 214, 218, 220, 222, 224,\n",
       "        226, 227, 229]),\n",
       " '_i52': 'ffp=np.where(efficientNetB2_pred[52:]==1)[0]\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nffp',\n",
       " '_52': array([  0,   3,   6,  11,  13,  14,  15,  16,  17,  19,  32,  35,  36,\n",
       "         38,  39,  41,  46,  48,  57,  60,  68,  69,  73,  74,  75,  79,\n",
       "         80,  81,  82,  86,  96,  99, 102, 105, 108, 109, 111, 112, 113,\n",
       "        115, 117, 121, 124, 133, 138, 141, 143, 145, 148, 156, 160, 169,\n",
       "        171, 177, 180]),\n",
       " '_i53': 'ffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)',\n",
       " '_i54': 'ffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nffp',\n",
       " '_54': array([ 52,  55,  58,  63,  65,  66,  67,  68,  69,  71,  84,  87,  88,\n",
       "         90,  91,  93,  98, 100, 109, 112, 120, 121, 125, 126, 127, 131,\n",
       "        132, 133, 134, 138, 148, 151, 154, 157, 160, 161, 163, 164, 165,\n",
       "        167, 169, 173, 176, 185, 190, 193, 195, 197, 200, 208, 212, 221,\n",
       "        223, 229, 232]),\n",
       " '_i55': 'ffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nffp[numbers]',\n",
       " '_55': array([160, 173, 190, 154, 223, 134,  65, 100,  84, 126,  88, 109, 138,\n",
       "        176,  67, 121,  98, 157]),\n",
       " '_i56': 'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB2_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 1, replace=False)\\nefficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nefficientNetB2_pred[ffp[numbers]]=0',\n",
       " 'ttp': array([ 2,  4,  6,  9, 14, 22, 28, 29, 31, 36, 39, 40, 41, 45, 47, 51]),\n",
       " '_i57': 'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB2_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 1, replace=False)\\nefficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nefficientNetB2_pred[ffp[numbers]]=0\\nefficientNetB3_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB3_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 43-36, replace=False)\\nefficientNetB3_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB3_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-43, replace=False)\\nefficientNetB3_pred[ffp[numbers]]=0',\n",
       " '_i58': 'efficientNetB3_pred',\n",
       " '_58': array([0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " '_i59': 'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB2_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 1, replace=False)\\nefficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nefficientNetB2_pred[ffp[numbers]]=0\\nefficientNetB3_pred=inceptionResNetV2_pred\\nttp=np.where(efficientNetB3_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 43-36, replace=False)\\nefficientNetB3_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB3_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-43, replace=False)\\nefficientNetB3_pred[ffp[numbers]]=0',\n",
       " '_i60': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False) \",\n",
       " '_i61': 'inceptionResNetV2_cm=np.array([[36,16],[55,127]])\\nefficientNetB3_cm=np.array([[37,15],[37,145]])\\nefficientNetB2_cm=np.array([[43,9],[43,139]])\\ny_test=np.ones([52])\\ny_test=np.concatenate([y_test,np.zeros([182])])\\n\\ninceptionResNetV2_pred=np.zeros([len(y_test)])\\nnumbers = np.random.choice(range(0, 52), 36, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nnumbers = np.random.choice(range(52, len(y_test)), 55, replace=False)\\ninceptionResNetV2_pred[numbers]=1\\nefficientNetB2_pred=np.copy(inceptionResNetV2_pred)\\nttp=np.where(efficientNetB2_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 1, replace=False)\\nefficientNetB2_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB2_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-37, replace=False)\\nefficientNetB2_pred[ffp[numbers]]=0\\nefficientNetB3_pred=np.copy(inceptionResNetV2_pred)\\nttp=np.where(efficientNetB3_pred[:52]==0)[0]\\nnumbers = np.random.choice(range(0, len(ttp)), 43-36, replace=False)\\nefficientNetB3_pred[ttp[numbers]]=1\\nffp=np.where(efficientNetB3_pred[52:]==1)[0]+52\\nnumbers = np.random.choice(range(0, len(ffp)), 55-43, replace=False)\\nefficientNetB3_pred[ffp[numbers]]=0',\n",
       " '_i62': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha':[(1-alpha)*100],\\n                'Confidence Interval': [metric_value-confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False) \",\n",
       " '_i63': \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    \\n    metrics = {\\n        'Accuracy': accuracy,\\n        'Sensitivity': sensitivity,\\n        'Specificity': specificity,\\n        'F1 Score': f1\\n    }\\n\\n    return metrics\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    for metric_name, metric_value in calculate_performance_metrics(true_labels, results).items():\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i64': \"import pandas as pd\\nimport numpy as np\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    \\n    metrics = {\\n        'Accuracy': accuracy,\\n        'Sensitivity': sensitivity,\\n        'Specificity': specificity,\\n        'F1 Score': f1\\n    }\\n\\n    return metrics\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value', 'Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    for metric_name, metric_value in calculate_performance_metrics(true_labels, results).items():\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            \\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i65': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i66': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i67': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i68': 'confidence_interval',\n",
       " '_68': (0.5181467040987666, 0.7282301074954373),\n",
       " '_i69': 'metric_value',\n",
       " '_69': 0.6231884057971014,\n",
       " '_i70': 'metric_name',\n",
       " '_70': 'F1 Score',\n",
       " '_i71': \"for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n    print(metric_name)\",\n",
       " '_i72': \"for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n    print(metric_value)\",\n",
       " '_i73': \"for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n    for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\",\n",
       " '_i74': \"for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n    for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n            print(confidence_interval)\",\n",
       " '_i75': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 2\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i76': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i77': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i78': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n    \\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n    \\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n    \\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n    \\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1-alpha)*100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],  # 수정된 부분\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i79': 'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\nimport numpy as np\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, metric_name):\\n    if metric_name == \\'Accuracy\\':\\n        metric_value = accuracy_score(y_true, y_pred)\\n    elif metric_name == \\'Sensitivity\\':\\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n        metric_value = tp / (tp + fn)\\n    elif metric_name == \\'Specificity\\':\\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n        metric_value = tn / (tn + fp)\\n    elif metric_name == \\'F1 Score\\':\\n        metric_value = f1_score(y_true, y_pred)\\n    else:\\n        raise ValueError(\"Invalid metric name\")\\n\\n    return metric_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip([\\'inceptionResNetV2\\', \\'efficientNetB2\\', \\'efficientNetB3\\'], [results_model1, results_model2, results_model3]):\\n    for metric_name in [\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\']:\\n        metric_value = calculate_performance_metrics(true_labels, results, metric_name)\\n\\n        # Calculate p-value using t-test\\n        t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n        # Perform ANOVA\\n        _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n        # Apply Bonferroni correction to ANOVA p-value\\n        _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                \\'Model\\': [model],\\n                \\'Metric\\': [metric_name],\\n                \\'Value\\': [metric_value],\\n                \\'Alpha\\': [(1-alpha)*100],\\n                \\'Confidence Interval\\': [confidence_interval[1] - confidence_interval[0]],\\n                \\'p-value\\': [p_value_ttest],\\n                \\'ANOVA with bonferroni collection p-value\\': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       " '_i80': 'import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\nimport numpy as np\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred, metric_name):\\n    if metric_name == \\'Accuracy\\':\\n        metric_value = accuracy_score(y_true, y_pred)\\n    elif metric_name == \\'Sensitivity\\':\\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n        metric_value = tp / (tp + fn)\\n    elif metric_name == \\'Specificity\\':\\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n        metric_value = tn / (tn + fp)\\n    elif metric_name == \\'F1 Score\\':\\n        metric_value = f1_score(y_true, y_pred)\\n    else:\\n        raise ValueError(\"Invalid metric name\")\\n\\n    return metric_value\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=[\\'Model\\', \\'Metric\\', \\'Value\\', \\'Alpha\\', \\'Confidence Interval\\', \\'p-value\\', \\'ANOVA with bonferroni collection p-value\\'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip([\\'inceptionResNetV2\\', \\'efficientNetB2\\', \\'efficientNetB3\\'], [results_model1, results_model2, results_model3]):\\n    for metric_name in [\\'Accuracy\\', \\'Sensitivity\\', \\'Specificity\\', \\'F1 Score\\']:\\n        metric_value = calculate_performance_metrics(true_labels, results, metric_name)\\n\\n        # Calculate p-value using t-test\\n        t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n        # Perform ANOVA\\n        _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n        # Apply Bonferroni correction to ANOVA p-value\\n        _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method=\\'bonferroni\\')\\n\\n        for alpha in alpha_values:\\n            # t.interval 함수를 사용하여 신뢰구간 계산\\n            df = len(results) - 1\\n            confidence_interval = t.interval(1 - alpha, df, loc=metric_value, scale=np.std(results) / np.sqrt(len(results)))\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                \\'Model\\': [model],\\n                \\'Metric\\': [metric_name],\\n                \\'Value\\': [metric_value],\\n                \\'Alpha\\': [(1-alpha)*100],\\n                \\'Confidence Interval\\': [confidence_interval[1] - confidence_interval[0]],\\n                \\'p-value\\': [p_value_ttest],\\n                \\'ANOVA with bonferroni collection p-value\\': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv(\\'model_comparison_results.csv\\', index=False)',\n",
       " '_i81': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n\\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n\\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # Calculate standard error of the mean\\n            sem = np.std(results) / np.sqrt(len(results))\\n\\n            # Calculate confidence interval manually\\n            margin_of_error = t.ppf(1 - alpha / 2, len(results) - 1) * sem\\n            confidence_interval = (metric_value - margin_of_error, metric_value + margin_of_error)\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1 - alpha) * 100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " 'sem': 0.03186874262278788,\n",
       " 'margin_of_error': 0.10504170169833581,\n",
       " '_i82': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n\\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n\\n    for metric_name, metric_value in zip(['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], [accuracy, sensitivity, specificity, f1]):\\n        for alpha in alpha_values:\\n            # Calculate standard error of the mean\\n            sem = np.std(results) / np.sqrt(len(results))\\n\\n            # Calculate confidence interval manually\\n            margin_of_error = t.ppf(1 - alpha / 2, len(results) - 1) * sem\\n            confidence_interval = (metric_value - margin_of_error, metric_value + margin_of_error)\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1 - alpha) * 100],\\n                'Confidence Interval': [confidence_interval[1] - confidence_interval[0]],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " '_i83': 'sem = np.std(results) / np.sqrt(len(results))',\n",
       " '_i84': 'sem ',\n",
       " '_84': 0.031517829165165843,\n",
       " '_i85': \"import pandas as pd\\nfrom scipy.stats import t, ttest_ind, f_oneway\\nfrom statsmodels.stats.multitest import multipletests\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\\n\\n# 가상의 예제 데이터 생성\\ndata_model1 = inceptionResNetV2_pred\\ndata_model2 = efficientNetB2_pred\\ndata_model3 = efficientNetB3_pred\\n\\n# 이진분류 모델 3개의 결과를 각각 저장\\nresults_model1 = data_model1 > 0\\nresults_model2 = data_model2 > 0\\nresults_model3 = data_model3 > 0\\n\\ntrue_labels = y_test\\n\\n# 성능 지표 계산 함수\\ndef calculate_performance_metrics(y_true, y_pred):\\n    accuracy = accuracy_score(y_true, y_pred)\\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\\n    sensitivity = tp / (tp + fn)\\n    specificity = tn / (tn + fp)\\n    f1 = f1_score(y_true, y_pred)\\n    return accuracy, sensitivity, specificity, f1\\n\\nalpha_values = [0.2, 0.15, 0.1, 0.05, 0.025, 0.01, 0.005, 0.001]\\n\\n# 결과를 저장할 DataFrame 생성\\nresult_df = pd.DataFrame(columns=['Model', 'Metric', 'Value','Alpha', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\\n\\n# 각 모델에 대한 신뢰구간, p-value, ANOVA p-value 계산 및 DataFrame에 저장\\nfor model, results in zip(['inceptionResNetV2', 'efficientNetB2', 'efficientNetB3'], [results_model1, results_model2, results_model3]):\\n    accuracy, sensitivity, specificity, f1 = calculate_performance_metrics(true_labels, results)\\n\\n    # Calculate p-value using t-test\\n    t_statistic, p_value_ttest = ttest_ind(results, true_labels)\\n\\n    # Perform ANOVA\\n    _, p_value_anova = f_oneway(results_model1, results_model2, results_model3)\\n\\n    # Apply Bonferroni correction to ANOVA p-value\\n    _, p_value_anova_corrected, _, _ = multipletests([p_value_anova], method='bonferroni')\\n\\n    metrics = ['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score']\\n    \\n    for metric_name in metrics:\\n        metric_value = locals()[metric_name.lower()]  # Access the metric value dynamically\\n\\n        for alpha in alpha_values:\\n            # Calculate standard error of the mean\\n            sem = np.std(results) / np.sqrt(len(results))\\n\\n            # Calculate t-statistic for the given alpha\\n            t_value = t.ppf(1 - alpha / 2, len(results) - 1)\\n\\n            # Calculate lower and upper bounds of the confidence interval\\n            lower_bound = metric_value - t_value * sem\\n            upper_bound = metric_value + t_value * sem\\n\\n            # 결과를 DataFrame에 추가\\n            result_df = pd.concat([result_df, pd.DataFrame({\\n                'Model': [model],\\n                'Metric': [metric_name],\\n                'Value': [metric_value],\\n                'Alpha': [(1 - alpha) * 100],\\n                'Confidence Interval': [upper_bound - lower_bound],\\n                'p-value': [p_value_ttest],\\n                'ANOVA with bonferroni collection p-value': [p_value_anova_corrected[0]]\\n            })])\\n\\n# 결과 DataFrame 출력\\nprint(result_df)\\n# 결과 DataFrame을 CSV 파일로 저장 (필요에 따라 주석 처리)\\nresult_df.to_csv('model_comparison_results.csv', index=False)\",\n",
       " 'metrics': ['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'],\n",
       " 't_value': 3.3327708310072977,\n",
       " 'lower_bound': 0.5915909819680913,\n",
       " 'upper_bound': 0.8040134136363042,\n",
       " '_i86': ' metrics',\n",
       " '_86': ['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'],\n",
       " '_i87': ' metricsmetric_name.lower(',\n",
       " '_i88': ' metricsmetric_name.lower',\n",
       " '_i89': 'metricsmetric_name.lower',\n",
       " '_i90': 'locals()'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                                      |   ('Value', 0.2) |   ('Confidence Interval', 0.2) |   ('Confidence Interval', 0.15) |   ('Confidence Interval', 0.1) |   ('Confidence Interval', 0.05) |   ('Confidence Interval', 0.025) |   ('Confidence Interval', 0.01) |   ('Confidence Interval', 0.005) |   ('Confidence Interval', 0.001) |   ('p-value', 0.2) |   ('ANOVA with bonferroni collection p-value', 0.2) |   ('ANOVA with bonferroni collection p-value', 0.15) |   ('ANOVA with bonferroni collection p-value', 0.1) |   ('ANOVA with bonferroni collection p-value', 0.05) |   ('ANOVA with bonferroni collection p-value', 0.025) |   ('ANOVA with bonferroni collection p-value', 0.01) |   ('ANOVA with bonferroni collection p-value', 0.005) |   ('ANOVA with bonferroni collection p-value', 0.001) |\n",
      "|:-------------------------------------|-----------------:|-------------------------------:|--------------------------------:|-------------------------------:|--------------------------------:|---------------------------------:|--------------------------------:|---------------------------------:|---------------------------------:|-------------------:|----------------------------------------------------:|-----------------------------------------------------:|----------------------------------------------------:|-----------------------------------------------------:|------------------------------------------------------:|-----------------------------------------------------:|------------------------------------------------------:|------------------------------------------------------:|\n",
      "| ('efficientNetB2', 'Accuracy')       |         0.777778 |                      0.0405066 |                       0.045521  |                      0.0520492 |                       0.0620964 |                        0.0711036 |                       0.0818548 |                        0.089322  |                         0.105042 |        0.000540936 |                                            0.242462 |                                             0.242462 |                                            0.242462 |                                             0.242462 |                                              0.242462 |                                             0.242462 |                                              0.242462 |                                              0.242462 |\n",
      "| ('efficientNetB2', 'F1 Score')       |         0.623188 |                      0.0405066 |                       0.045521  |                      0.0520492 |                       0.0620964 |                        0.0711036 |                       0.0818548 |                        0.089322  |                         0.105042 |        0.000540936 |                                            0.242462 |                                             0.242462 |                                            0.242462 |                                             0.242462 |                                              0.242462 |                                             0.242462 |                                              0.242462 |                                              0.242462 |\n",
      "| ('efficientNetB2', 'Sensitivity')    |         0.826923 |                      0.0405066 |                       0.045521  |                      0.0520492 |                       0.0620964 |                        0.0711036 |                       0.0818548 |                        0.089322  |                         0.105042 |        0.000540936 |                                            0.242462 |                                             0.242462 |                                            0.242462 |                                             0.242462 |                                              0.242462 |                                             0.242462 |                                              0.242462 |                                              0.242462 |\n",
      "| ('efficientNetB2', 'Specificity')    |         0.763736 |                      0.0405066 |                       0.045521  |                      0.0520492 |                       0.0620964 |                        0.0711036 |                       0.0818548 |                        0.089322  |                         0.105042 |        0.000540936 |                                            0.242462 |                                             0.242462 |                                            0.242462 |                                             0.242462 |                                              0.242462 |                                             0.242462 |                                              0.242462 |                                              0.242462 |\n",
      "| ('efficientNetB3', 'Accuracy')       |         0.777778 |                      0.039068  |                       0.0439043 |                      0.0502007 |                       0.059891  |                        0.0685784 |                       0.0789477 |                        0.0861498 |                         0.101311 |        0.0218463   |                                            0.242462 |                                             0.242462 |                                            0.242462 |                                             0.242462 |                                              0.242462 |                                             0.242462 |                                              0.242462 |                                              0.242462 |\n",
      "| ('efficientNetB3', 'F1 Score')       |         0.587302 |                      0.039068  |                       0.0439043 |                      0.0502007 |                       0.059891  |                        0.0685784 |                       0.0789477 |                        0.0861498 |                         0.101311 |        0.0218463   |                                            0.242462 |                                             0.242462 |                                            0.242462 |                                             0.242462 |                                              0.242462 |                                             0.242462 |                                              0.242462 |                                              0.242462 |\n",
      "| ('efficientNetB3', 'Sensitivity')    |         0.711538 |                      0.039068  |                       0.0439043 |                      0.0502007 |                       0.059891  |                        0.0685784 |                       0.0789477 |                        0.0861498 |                         0.101311 |        0.0218463   |                                            0.242462 |                                             0.242462 |                                            0.242462 |                                             0.242462 |                                              0.242462 |                                             0.242462 |                                              0.242462 |                                              0.242462 |\n",
      "| ('efficientNetB3', 'Specificity')    |         0.796703 |                      0.039068  |                       0.0439043 |                      0.0502007 |                       0.059891  |                        0.0685784 |                       0.0789477 |                        0.0861498 |                         0.101311 |        0.0218463   |                                            0.242462 |                                             0.242462 |                                            0.242462 |                                             0.242462 |                                              0.242462 |                                             0.242462 |                                              0.242462 |                                              0.242462 |\n",
      "| ('inceptionResNetV2', 'Accuracy')    |         0.696581 |                      0.0409576 |                       0.0460278 |                      0.0526287 |                       0.0627877 |                        0.0718953 |                       0.0827661 |                        0.0903165 |                         0.106211 |        8.29662e-05 |                                            0.242462 |                                             0.242462 |                                            0.242462 |                                             0.242462 |                                              0.242462 |                                             0.242462 |                                              0.242462 |                                              0.242462 |\n",
      "| ('inceptionResNetV2', 'F1 Score')    |         0.503497 |                      0.0409576 |                       0.0460278 |                      0.0526287 |                       0.0627877 |                        0.0718953 |                       0.0827661 |                        0.0903165 |                         0.106211 |        8.29662e-05 |                                            0.242462 |                                             0.242462 |                                            0.242462 |                                             0.242462 |                                              0.242462 |                                             0.242462 |                                              0.242462 |                                              0.242462 |\n",
      "| ('inceptionResNetV2', 'Sensitivity') |         0.692308 |                      0.0409576 |                       0.0460278 |                      0.0526287 |                       0.0627877 |                        0.0718953 |                       0.0827661 |                        0.0903165 |                         0.106211 |        8.29662e-05 |                                            0.242462 |                                             0.242462 |                                            0.242462 |                                             0.242462 |                                              0.242462 |                                             0.242462 |                                              0.242462 |                                              0.242462 |\n",
      "| ('inceptionResNetV2', 'Specificity') |         0.697802 |                      0.0409576 |                       0.0460278 |                      0.0526287 |                       0.0627877 |                        0.0718953 |                       0.0827661 |                        0.0903165 |                         0.106211 |        8.29662e-05 |                                            0.242462 |                                             0.242462 |                                            0.242462 |                                             0.242462 |                                              0.242462 |                                             0.242462 |                                              0.242462 |                                              0.242462 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일에서 데이터 읽기\n",
    "csv_file = 'model_comparison_results.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 데이터를 원하는 형식으로 가공\n",
    "table = df.pivot_table(index=['Model', 'Metric'], columns='Alpha', values=['Value', 'Confidence Interval', 'p-value', 'ANOVA with bonferroni collection p-value'])\n",
    "\n",
    "# 워드 논문 형식에 맞게 컬럼 정렬\n",
    "table = table[[('Value', 0.2),\n",
    "               ('Confidence Interval', 0.2), ('Confidence Interval', 0.15), ('Confidence Interval', 0.1), ('Confidence Interval', 0.05), ('Confidence Interval', 0.025), ('Confidence Interval', 0.01), ('Confidence Interval', 0.005), ('Confidence Interval', 0.001),\n",
    "               ('p-value', 0.2),\n",
    "               ('ANOVA with bonferroni collection p-value', 0.2), ('ANOVA with bonferroni collection p-value', 0.15), ('ANOVA with bonferroni collection p-value', 0.1), ('ANOVA with bonferroni collection p-value', 0.05), ('ANOVA with bonferroni collection p-value', 0.025), ('ANOVA with bonferroni collection p-value', 0.01), ('ANOVA with bonferroni collection p-value', 0.005), ('ANOVA with bonferroni collection p-value', 0.001)]]\n",
    "\n",
    "# 워드 표 형식으로 출력\n",
    "print(table.to_markdown())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Accuracy\n",
       "0    Accuracy\n",
       "0    Accuracy\n",
       "0    Accuracy\n",
       "0    Accuracy\n",
       "       ...   \n",
       "0         AUC\n",
       "0         AUC\n",
       "0         AUC\n",
       "0         AUC\n",
       "0         AUC\n",
       "Name: Metric, Length: 120, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.loc[0, 'Metric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T-test and p-value for Model 1:\n",
      "  Accuracy: 46.00%\n",
      "    t-statistic: -10.780417028313323, p-value: 1.2866965296964952e-21\n",
      "  Precision: 100.00%\n",
      "    t-statistic: -10.780417028313323, p-value: 1.2866965296964952e-21\n",
      "  Recall: 46.00%\n",
      "    t-statistic: -10.780417028313323, p-value: 1.2866965296964952e-21\n",
      "  F1 Score: 63.01%\n",
      "    t-statistic: -10.780417028313323, p-value: 1.2866965296964952e-21\n",
      "\n",
      "T-test and p-value for Model 2:\n",
      "  Accuracy: 68.00%\n",
      "    t-statistic: -6.825557507934252, p-value: 1.0449223161892874e-10\n",
      "  Precision: 100.00%\n",
      "    t-statistic: -6.825557507934252, p-value: 1.0449223161892874e-10\n",
      "  Recall: 68.00%\n",
      "    t-statistic: -6.825557507934252, p-value: 1.0449223161892874e-10\n",
      "  F1 Score: 80.95%\n",
      "    t-statistic: -6.825557507934252, p-value: 1.0449223161892874e-10\n",
      "\n",
      "T-test and p-value for Model 3:\n",
      "  Accuracy: 85.00%\n",
      "    t-statistic: -4.179783276115416, p-value: 4.377094840750872e-05\n",
      "  Precision: 100.00%\n",
      "    t-statistic: -4.179783276115416, p-value: 4.377094840750872e-05\n",
      "  Recall: 85.00%\n",
      "    t-statistic: -4.179783276115416, p-value: 4.377094840750872e-05\n",
      "  F1 Score: 91.89%\n",
      "    t-statistic: -4.179783276115416, p-value: 4.377094840750872e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py:523: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t, ttest_ind\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 가상의 예제 데이터 생성\n",
    "np.random.seed(42)\n",
    "data_model1 = np.random.normal(loc=0, scale=1, size=100)\n",
    "data_model2 = np.random.normal(loc=0.5, scale=1, size=100)\n",
    "data_model3 = np.random.normal(loc=1, scale=1, size=100)\n",
    "\n",
    "# 이진분류 모델 3개의 결과를 각각 저장\n",
    "results_model1 = (data_model1 > 0).astype(int)\n",
    "results_model2 = (data_model2 > 0).astype(int)\n",
    "results_model3 = (data_model3 > 0).astype(int)\n",
    "\n",
    "# 실제 라벨 (예시로 모두 1로 설정)\n",
    "true_labels = np.ones_like(data_model1)\n",
    "\n",
    "# 성능 지표 계산 함수\n",
    "def calculate_performance_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# 각 모델에 대한 t-test 및 p-value 계산 및 출력\n",
    "for model, results in zip(['Model 1', 'Model 2', 'Model 3'], [results_model1, results_model2, results_model3]):\n",
    "    accuracy, precision, recall, f1 = calculate_performance_metrics(true_labels, results)\n",
    "    \n",
    "    print(f\"\\nT-test and p-value for {model}:\")\n",
    "    for metric_name, metric_value in zip(['Accuracy', 'Precision', 'Recall', 'F1 Score'], [accuracy, precision, recall, f1]):\n",
    "        print(f\"  {metric_name}: {metric_value:.2%}\")\n",
    "        t_statistic, p_value = ttest_ind(results, true_labels)\n",
    "        print(f\"    t-statistic: {t_statistic}, p-value: {p_value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
