{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 14:27:39.246180: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-20 14:27:39.873274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms,datasets\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size':8,\n",
    "    'num_epoch':200,\n",
    "    'lr':2e-3,\n",
    "    'log_dir':'../../data/CycleGANData/wholeslide/',\n",
    "    'img_form':'tiff'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataLoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs,mask,classes, imgsz=(512, 512, 3), transform=None):\n",
    "        self.th, self.tw, self.tc = imgsz  # target-height, target-width, target-channel\n",
    "        self.image = imgs\n",
    "        self.label = mask\n",
    "        self.category_count=classes\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = np.array(Image.open(self.image[index]))\n",
    "        annot = np.array(Image.open(self.label[index]))\n",
    "        annot = annot.astype(np.float32)\n",
    "        img = img.astype(np.float32)\n",
    "        annot  = annot /255.0\n",
    "        img = img/255.0\n",
    "        \n",
    "\n",
    "        \n",
    "        if annot.ndim == 2:  \n",
    "            annot = annot[:,:,np.newaxis]\n",
    "        if img.ndim == 2:  \n",
    "            img = img[:,:,np.newaxis] \n",
    "            \n",
    "        data = {'input':img, 'label':annot}   \n",
    "        \n",
    "        if self.transform:\t\t\t\t\n",
    "            data = self.transform(data)\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "    \n",
    "class ToTensor(object):\n",
    "    def __call__(self, data):\n",
    "        label, input = data['label'], data['input']\n",
    "\t\t\n",
    "        # numpy와 tensor의 배열 차원 순서가 다르다. \n",
    "        # numpy : (행, 열, 채널)\n",
    "        # tensor : (채널, 행, 열)\n",
    "        # 따라서 위 순서에 맞춰 transpose\n",
    "        \n",
    "        label = label.transpose((2, 0, 1)).astype(np.float32) \n",
    "        input = input.transpose((2, 0, 1)).astype(np.float32)\n",
    "\t\t\n",
    "        # 이후 np를 tensor로 바꾸는 코드는 다음과 같이 간단하다.\n",
    "        data = {'label': torch.from_numpy(label), 'input': torch.from_numpy(input)}\n",
    "\n",
    "        return data\n",
    "    \n",
    "class Normalization(object):\n",
    "    def __init__(self, mean=0.5, std=0.5):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, data):\n",
    "        label, input = data['label'], data['input']\n",
    "\n",
    "        input = (input - self.mean) / self.std\n",
    "\n",
    "        data = {'label': label, 'input': input}\n",
    "\n",
    "        return data\n",
    "\n",
    "class RandomFlip(object):\n",
    "    def __call__(self, data):\n",
    "        label, input = data['label'], data['input']\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            label = np.fliplr(label)\n",
    "            input = np.fliplr(input)\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            label = np.flipud(label)\n",
    "            input = np.flipud(input)\n",
    "\n",
    "        data = {'label': label, 'input': input}\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=glob('../../data/CycleGANData/wholeslide/image/*.'+params['img_form'])\n",
    "masks=[f.replace('/image', '/mask') for f in imgs]\n",
    "transform = transforms.Compose([Normalization(mean=0.5, std=0.5), RandomFlip(), ToTensor()])\n",
    "dataset = CustomDataset(imgs=imgs,mask=masks,classes=1,transform=transform)\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "validation_size = int(len(dataset) * 0.1)\n",
    "test_size = len(dataset) - train_size - validation_size\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "loader_train = DataLoader(train_dataset, batch_size =params['batch_size'], shuffle=True)\n",
    "loader_validation = DataLoader(validation_dataset, batch_size = params['batch_size'], shuffle=True)\n",
    "loader_test = DataLoader(test_dataset, batch_size = params['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 네트워크 구축\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        def CBR2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                 bias=bias)]\n",
    "            layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        # Contracting path\n",
    "        self.enc1_1 = CBR2d(in_channels=3, out_channels=64)\n",
    "        self.enc1_2 = CBR2d(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc2_1 = CBR2d(in_channels=64, out_channels=128)\n",
    "        self.enc2_2 = CBR2d(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc3_1 = CBR2d(in_channels=128, out_channels=256)\n",
    "        self.enc3_2 = CBR2d(in_channels=256, out_channels=256)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc4_1 = CBR2d(in_channels=256, out_channels=512)\n",
    "        self.enc4_2 = CBR2d(in_channels=512, out_channels=512)\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc5_1 = CBR2d(in_channels=512, out_channels=1024)\n",
    "\n",
    "        # Expansive path\n",
    "        self.dec5_1 = CBR2d(in_channels=1024, out_channels=512)\n",
    "\n",
    "        self.unpool4 = nn.ConvTranspose2d(in_channels=512, out_channels=512,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec4_2 = CBR2d(in_channels=2 * 512, out_channels=512)\n",
    "        self.dec4_1 = CBR2d(in_channels=512, out_channels=256)\n",
    "\n",
    "        self.unpool3 = nn.ConvTranspose2d(in_channels=256, out_channels=256,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec3_2 = CBR2d(in_channels=2 * 256, out_channels=256)\n",
    "        self.dec3_1 = CBR2d(in_channels=256, out_channels=128)\n",
    "\n",
    "        self.unpool2 = nn.ConvTranspose2d(in_channels=128, out_channels=128,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec2_2 = CBR2d(in_channels=2 * 128, out_channels=128)\n",
    "        self.dec2_1 = CBR2d(in_channels=128, out_channels=64)\n",
    "\n",
    "        self.unpool1 = nn.ConvTranspose2d(in_channels=64, out_channels=64,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec1_2 = CBR2d(in_channels=2 * 64, out_channels=64)\n",
    "        self.dec1_1 = CBR2d(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.fc = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "\n",
    "        dec5_1 = self.dec5_1(enc5_1)\n",
    "\n",
    "        unpool4 = self.unpool4(dec5_1)\n",
    "        cat4 = torch.cat((unpool4, enc4_2), dim=1)\n",
    "        dec4_2 = self.dec4_2(cat4)\n",
    "        dec4_1 = self.dec4_1(dec4_2)\n",
    "\n",
    "        unpool3 = self.unpool3(dec4_1)\n",
    "        cat3 = torch.cat((unpool3, enc3_2), dim=1)\n",
    "        dec3_2 = self.dec3_2(cat3)\n",
    "        dec3_1 = self.dec3_1(dec3_2)\n",
    "\n",
    "        unpool2 = self.unpool2(dec3_1)\n",
    "        cat2 = torch.cat((unpool2, enc2_2), dim=1)\n",
    "        dec2_2 = self.dec2_2(cat2)\n",
    "        dec2_1 = self.dec2_1(dec2_2)\n",
    "\n",
    "        unpool1 = self.unpool1(dec2_1)\n",
    "        cat1 = torch.cat((unpool1, enc1_2), dim=1)\n",
    "        dec1_2 = self.dec1_2(cat1)\n",
    "        dec1_1 = self.dec1_1(dec1_2)\n",
    "\n",
    "        x = self.fc(dec1_1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet().to(device)\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        inputs = F.sigmoid(inputs) # sigmoid를 통과한 출력이면 주석처리\n",
    "        \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth) / (inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice \n",
    "fn_loss = DiceLoss().to(device)\n",
    "# Optimizer 정의\n",
    "optim = torch.optim.Adam(net.parameters(),lr = params['lr'] ) \n",
    "\n",
    "# 기타 variables 설정\n",
    "num_train = len(train_dataset)\n",
    "num_val = len(validation_dataset)\n",
    "\n",
    "num_train_for_epoch = np.ceil(num_train/params['batch_size']) # np.ceil : 소수점 반올림\n",
    "num_val_for_epoch = np.ceil(num_val/params['batch_size'])\n",
    "\n",
    "# 기타 function 설정\n",
    "fn_tonumpy = lambda x : x.to('cpu').detach().numpy().transpose(0,2,3,1) # device 위에 올라간 텐서를 detach 한 뒤 numpy로 변환\n",
    "fn_denorm = lambda x, mean, std : (x * std) + mean \n",
    "fn_classifier = lambda x :  1.0 * (x > 0.5)  # threshold 0.5 기준으로 indicator function으로 classifier 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_optimization_loss=2\n",
    "train_loss_list=[]\n",
    "validation_loss_list=[]\n",
    "for epoch in range(params['num_epoch']):\n",
    "    net.train()\n",
    "    loss_arr = []\n",
    "    validation_losses=[]\n",
    "    ae=tqdm_notebook(loader_train)\n",
    "    for batch, data in enumerate(ae): # 1은 뭐니 > index start point\n",
    "        # forward\n",
    "        label = data['label'].to(device)   # 데이터 device로 올리기     \n",
    "        inputs = data['input'].to(device)\n",
    "        output = net(inputs) \n",
    "\n",
    "        # backward\n",
    "        optim.zero_grad()  # gradient 초기화\n",
    "        loss = fn_loss(output,label)  # output과 label 사이의 loss 계산\n",
    "        loss.backward() # gradient backpropagation\n",
    "        optim.step() # backpropa 된 gradient를 이용해서 각 layer의 parameters update\n",
    "\n",
    "        # save loss\n",
    "        loss_arr += [loss.item()]\n",
    "\n",
    "        # tensorbord에 결과값들 저정하기\n",
    "        label = fn_tonumpy(label)\n",
    "        inputs = fn_tonumpy(fn_denorm(inputs,0.5,0.5))\n",
    "        output = fn_tonumpy(fn_classifier(output))\n",
    "        ae.set_description(f\"epoch: {epoch+1}/{params['num_epoch']} loss :{loss.item():.4f}\") \n",
    "         \n",
    "    #validatoin\n",
    "    \n",
    "    for batch, data in enumerate(loader_validation): # 1은 뭐니 > index start point\n",
    "        # forward\n",
    "        label = data['label'].to(device)   # 데이터 device로 올리기     \n",
    "        inputs = data['input'].to(device)\n",
    "        output = net(inputs) \n",
    "\n",
    "  \n",
    "        loss = fn_loss(output,label)  # output과 label 사이의 loss 계산\n",
    "        # save loss\n",
    "        validation_losses += [loss.item()]\n",
    "    print(f\"Train loss: {np.array(loss_arr).mean():.4f} val_loss: {np.array(validation_losses).mean():.4f}\")\n",
    "    train_loss_list.append(np.array(loss_arr).mean())\n",
    "    validation_loss_list.append(np.array(validation_losses).mean())\n",
    "    if validation_optimization_loss>=np.array(validation_losses).mean():\n",
    "        validation_optimization_loss=np.array(validation_losses).mean()\n",
    "        torch.save(net,'../../model/seg/optimization_loss.pt')\n",
    "    fig = plt.figure()\n",
    "    rows = 1\n",
    "    cols = 3\n",
    "    ax1 = fig.add_subplot(rows, cols, 1)\n",
    "    ax1.imshow(inputs[0].to('cpu').transpose(2,0))\n",
    "    ax1.set_title('img')\n",
    "    ax1.axis(\"off\")\n",
    "    \n",
    "    ax2 = fig.add_subplot(rows, cols, 2)\n",
    "    ax2.imshow(label[0].to('cpu').transpose(2,0))\n",
    "    ax2.set_title('ground_truth')\n",
    "    ax2.axis(\"off\")   \n",
    "    ax3 = fig.add_subplot(rows, cols, 3)\n",
    "    ax3.imshow(F.sigmoid(output[0]).to('cpu').transpose(2,0).detach().numpy())\n",
    "    ax3.set_title('pred')\n",
    "    ax3.axis(\"off\") \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m loss \u001b[39m=\u001b[39m fn_loss(output,label)  \u001b[39m# output과 label 사이의 loss 계산\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m8\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m     output_img\u001b[39m=\u001b[39mF\u001b[39m.\u001b[39msigmoid(output[i])\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     12\u001b[0m     output_img\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mwhere(output_img\u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,\u001b[39m255\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint16)\n\u001b[1;32m     13\u001b[0m     label_img\u001b[39m=\u001b[39mlabel[i]\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\u001b[39m*\u001b[39m\u001b[39m255\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "test_losses=[]\n",
    "count=0\n",
    "for batch, data in enumerate(loader_test): # 1은 뭐니 > index start point\n",
    "        \n",
    "        label = data['label'].to(device)   # 데이터 device로 올리기     \n",
    "        inputs = data['input'].to(device)\n",
    "                \n",
    "        output = net(inputs) \n",
    "        loss = fn_loss(output,label)  # output과 label 사이의 loss 계산\n",
    "        for i in range(8):\n",
    "            output_img=F.sigmoid(output[i]).to('cpu').transpose(2,0).detach().numpy()\n",
    "            output_img=np.where(output_img>=0.5,255,0).astype(np.int16)\n",
    "            label_img=label[i].to('cpu').transpose(2,0).detach().numpy()*255\n",
    "            label_img=label_img.astype(np.int16)\n",
    "            inputs_img=inputs[i].to('cpu').transpose(2,0).detach().numpy()*255\n",
    "            inputs_img=inputs_img.astype(np.float32)\n",
    "            cv2.imwrite('../../data/segmentation/pred/'+str(count)+'.png', output_img) \n",
    "            cv2.imwrite('../../data/segmentation/mask/'+str(count)+'.png', label_img) \n",
    "            cv2.imwrite('../../data/segmentation/image/'+str(count)+'.png', cv2.cvtColor(inputs_img, cv2.COLOR_BGR2RGB)) \n",
    "            count+=1\n",
    "            \n",
    "            # save loss\n",
    "        test_losses += [loss.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "output_img=F.sigmoid(output[0]).to('cpu').transpose(2,0).detach().numpy()\n",
    "output_img=np.where(output_img>=0.5,255,0).astype(np.int16)\n",
    "plt.imshow(output_img)\n",
    "cv2.imwrite('sample_out_2.png', cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /croot/opencv-suite_1676452025216/work/modules/imgproc/src/color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<3, 4>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = cv::impl::<unnamed>::NONE; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 3 (CV_16S)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cv2\u001b[39m.\u001b[39;49mcvtColor(inputs_img, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2RGB)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /croot/opencv-suite_1676452025216/work/modules/imgproc/src/color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<3, 4>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = cv::impl::<unnamed>::NONE; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 3 (CV_16S)\n"
     ]
    }
   ],
   "source": [
    "cv2.cvtColor(inputs_img, cv2.COLOR_BGR2RGB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
