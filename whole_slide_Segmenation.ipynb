{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms,datasets\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size':8,\n",
    "    'num_epoch':200,\n",
    "    'lr':2e-3,\n",
    "    'log_dir':'../../data/CycleGANData/wholeslide/',\n",
    "    'img_form':'tiff'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataLoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs,mask,classes, imgsz=(512, 512, 3), transform=None):\n",
    "        self.th, self.tw, self.tc = imgsz  # target-height, target-width, target-channel\n",
    "        self.image = imgs\n",
    "        self.label = mask\n",
    "        self.category_count=classes\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = np.array(Image.open(self.image[index]))\n",
    "        annot = np.array(Image.open(self.label[index]))\n",
    "        annot = annot.astype(np.float32)\n",
    "        img = img.astype(np.float32)\n",
    "        annot  = annot /255.0\n",
    "        img = img/255.0\n",
    "        \n",
    "\n",
    "        \n",
    "        if annot.ndim == 2:  \n",
    "            annot = annot[:,:,np.newaxis]\n",
    "        if img.ndim == 2:  \n",
    "            img = img[:,:,np.newaxis] \n",
    "            \n",
    "        data = {'input':img, 'label':annot}   \n",
    "        \n",
    "        if self.transform:\t\t\t\t\n",
    "            data = self.transform(data)\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "    \n",
    "class ToTensor(object):\n",
    "    def __call__(self, data):\n",
    "        label, input = data['label'], data['input']\n",
    "\t\t\n",
    "        # numpy와 tensor의 배열 차원 순서가 다르다. \n",
    "        # numpy : (행, 열, 채널)\n",
    "        # tensor : (채널, 행, 열)\n",
    "        # 따라서 위 순서에 맞춰 transpose\n",
    "        \n",
    "        label = label.transpose((2, 0, 1)).astype(np.float32) \n",
    "        input = input.transpose((2, 0, 1)).astype(np.float32)\n",
    "\t\t\n",
    "        # 이후 np를 tensor로 바꾸는 코드는 다음과 같이 간단하다.\n",
    "        data = {'label': torch.from_numpy(label), 'input': torch.from_numpy(input)}\n",
    "\n",
    "        return data\n",
    "    \n",
    "class Normalization(object):\n",
    "    def __init__(self, mean=0.5, std=0.5):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, data):\n",
    "        label, input = data['label'], data['input']\n",
    "\n",
    "        input = (input - self.mean) / self.std\n",
    "\n",
    "        data = {'label': label, 'input': input}\n",
    "\n",
    "        return data\n",
    "\n",
    "class RandomFlip(object):\n",
    "    def __call__(self, data):\n",
    "        label, input = data['label'], data['input']\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            label = np.fliplr(label)\n",
    "            input = np.fliplr(input)\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            label = np.flipud(label)\n",
    "            input = np.flipud(input)\n",
    "\n",
    "        data = {'label': label, 'input': input}\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=glob('../../data/CycleGANData/wholeslide/image/*.'+params['img_form'])\n",
    "masks=[f.replace('/image', '/mask') for f in imgs]\n",
    "transform = transforms.Compose([Normalization(mean=0.5, std=0.5), RandomFlip(), ToTensor()])\n",
    "dataset = CustomDataset(imgs=imgs,mask=masks,classes=1,transform=transform)\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "validation_size = int(len(dataset) * 0.1)\n",
    "test_size = len(dataset) - train_size - validation_size\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "loader_train = DataLoader(train_dataset, batch_size =params['batch_size'], shuffle=True)\n",
    "loader_validation = DataLoader(validation_dataset, batch_size = params['batch_size'], shuffle=True)\n",
    "loader_test = DataLoader(test_dataset, batch_size = params['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 네트워크 구축\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        def CBR2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                 bias=bias)]\n",
    "            layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        # Contracting path\n",
    "        self.enc1_1 = CBR2d(in_channels=3, out_channels=64)\n",
    "        self.enc1_2 = CBR2d(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc2_1 = CBR2d(in_channels=64, out_channels=128)\n",
    "        self.enc2_2 = CBR2d(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc3_1 = CBR2d(in_channels=128, out_channels=256)\n",
    "        self.enc3_2 = CBR2d(in_channels=256, out_channels=256)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc4_1 = CBR2d(in_channels=256, out_channels=512)\n",
    "        self.enc4_2 = CBR2d(in_channels=512, out_channels=512)\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc5_1 = CBR2d(in_channels=512, out_channels=1024)\n",
    "\n",
    "        # Expansive path\n",
    "        self.dec5_1 = CBR2d(in_channels=1024, out_channels=512)\n",
    "\n",
    "        self.unpool4 = nn.ConvTranspose2d(in_channels=512, out_channels=512,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec4_2 = CBR2d(in_channels=2 * 512, out_channels=512)\n",
    "        self.dec4_1 = CBR2d(in_channels=512, out_channels=256)\n",
    "\n",
    "        self.unpool3 = nn.ConvTranspose2d(in_channels=256, out_channels=256,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec3_2 = CBR2d(in_channels=2 * 256, out_channels=256)\n",
    "        self.dec3_1 = CBR2d(in_channels=256, out_channels=128)\n",
    "\n",
    "        self.unpool2 = nn.ConvTranspose2d(in_channels=128, out_channels=128,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec2_2 = CBR2d(in_channels=2 * 128, out_channels=128)\n",
    "        self.dec2_1 = CBR2d(in_channels=128, out_channels=64)\n",
    "\n",
    "        self.unpool1 = nn.ConvTranspose2d(in_channels=64, out_channels=64,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec1_2 = CBR2d(in_channels=2 * 64, out_channels=64)\n",
    "        self.dec1_1 = CBR2d(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.fc = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "\n",
    "        dec5_1 = self.dec5_1(enc5_1)\n",
    "\n",
    "        unpool4 = self.unpool4(dec5_1)\n",
    "        cat4 = torch.cat((unpool4, enc4_2), dim=1)\n",
    "        dec4_2 = self.dec4_2(cat4)\n",
    "        dec4_1 = self.dec4_1(dec4_2)\n",
    "\n",
    "        unpool3 = self.unpool3(dec4_1)\n",
    "        cat3 = torch.cat((unpool3, enc3_2), dim=1)\n",
    "        dec3_2 = self.dec3_2(cat3)\n",
    "        dec3_1 = self.dec3_1(dec3_2)\n",
    "\n",
    "        unpool2 = self.unpool2(dec3_1)\n",
    "        cat2 = torch.cat((unpool2, enc2_2), dim=1)\n",
    "        dec2_2 = self.dec2_2(cat2)\n",
    "        dec2_1 = self.dec2_1(dec2_2)\n",
    "\n",
    "        unpool1 = self.unpool1(dec2_1)\n",
    "        cat1 = torch.cat((unpool1, enc1_2), dim=1)\n",
    "        dec1_2 = self.dec1_2(cat1)\n",
    "        dec1_1 = self.dec1_1(dec1_2)\n",
    "\n",
    "        x = self.fc(dec1_1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet().to(device)\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        inputs = F.sigmoid(inputs) # sigmoid를 통과한 출력이면 주석처리\n",
    "        \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth) / (inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice \n",
    "fn_loss = DiceLoss().to(device)\n",
    "# Optimizer 정의\n",
    "optim = torch.optim.Adam(net.parameters(),lr = params['lr'] ) \n",
    "\n",
    "# 기타 variables 설정\n",
    "num_train = len(train_dataset)\n",
    "num_val = len(validation_dataset)\n",
    "\n",
    "num_train_for_epoch = np.ceil(num_train/params['batch_size']) # np.ceil : 소수점 반올림\n",
    "num_val_for_epoch = np.ceil(num_val/params['batch_size'])\n",
    "\n",
    "# 기타 function 설정\n",
    "fn_tonumpy = lambda x : x.to('cpu').detach().numpy().transpose(0,2,3,1) # device 위에 올라간 텐서를 detach 한 뒤 numpy로 변환\n",
    "fn_denorm = lambda x, mean, std : (x * std) + mean \n",
    "fn_classifier = lambda x :  1.0 * (x > 0.5)  # threshold 0.5 기준으로 indicator function으로 classifier 구현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_optimization_loss=2\n",
    "train_loss_list=[]\n",
    "validation_loss_list=[]\n",
    "for epoch in range(params['num_epoch']):\n",
    "    net.train()\n",
    "    loss_arr = []\n",
    "    validation_losses=[]\n",
    "    ae=tqdm_notebook(loader_train)\n",
    "    for batch, data in enumerate(ae): # 1은 뭐니 > index start point\n",
    "        # forward\n",
    "        label = data['label'].to(device)   # 데이터 device로 올리기     \n",
    "        inputs = data['input'].to(device)\n",
    "        output = net(inputs) \n",
    "\n",
    "        # backward\n",
    "        optim.zero_grad()  # gradient 초기화\n",
    "        loss = fn_loss(output,label)  # output과 label 사이의 loss 계산\n",
    "        loss.backward() # gradient backpropagation\n",
    "        optim.step() # backpropa 된 gradient를 이용해서 각 layer의 parameters update\n",
    "\n",
    "        # save loss\n",
    "        loss_arr += [loss.item()]\n",
    "\n",
    "        # tensorbord에 결과값들 저정하기\n",
    "        label = fn_tonumpy(label)\n",
    "        inputs = fn_tonumpy(fn_denorm(inputs,0.5,0.5))\n",
    "        output = fn_tonumpy(fn_classifier(output))\n",
    "        ae.set_description(f\"epoch: {epoch+1}/{params['num_epoch']} loss :{loss.item():.4f}\") \n",
    "         \n",
    "    #validatoin\n",
    "    \n",
    "    for batch, data in enumerate(loader_validation): # 1은 뭐니 > index start point\n",
    "        # forward\n",
    "        label = data['label'].to(device)   # 데이터 device로 올리기     \n",
    "        inputs = data['input'].to(device)\n",
    "        output = net(inputs) \n",
    "\n",
    "  \n",
    "        loss = fn_loss(output,label)  # output과 label 사이의 loss 계산\n",
    "        # save loss\n",
    "        validation_losses += [loss.item()]\n",
    "    print(f\"Train loss: {np.array(loss_arr).mean():.4f} val_loss: {np.array(validation_losses).mean():.4f}\")\n",
    "    train_loss_list.append(np.array(loss_arr).mean())\n",
    "    validation_loss_list.append(np.array(validation_losses).mean())\n",
    "    if validation_optimization_loss>=np.array(validation_losses).mean():\n",
    "        validation_optimization_loss=np.array(validation_losses).mean()\n",
    "        torch.save(net,'../../model/seg/optimization_loss.pt')\n",
    "    fig = plt.figure()\n",
    "    rows = 1\n",
    "    cols = 3\n",
    "    ax1 = fig.add_subplot(rows, cols, 1)\n",
    "    ax1.imshow(inputs[0].to('cpu').transpose(2,0))\n",
    "    ax1.set_title('img')\n",
    "    ax1.axis(\"off\")\n",
    "    \n",
    "    ax2 = fig.add_subplot(rows, cols, 2)\n",
    "    ax2.imshow(label[0].to('cpu').transpose(2,0))\n",
    "    ax2.set_title('ground_truth')\n",
    "    ax2.axis(\"off\")   \n",
    "    ax3 = fig.add_subplot(rows, cols, 3)\n",
    "    ax3.imshow(F.sigmoid(output[0]).to('cpu').transpose(2,0).detach().numpy())\n",
    "    ax3.set_title('pred')\n",
    "    ax3.axis(\"off\") \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses=[]\n",
    "for batch, data in enumerate(loader_test): # 1은 뭐니 > index start point\n",
    "        # forward\n",
    "        label = data['label'].to(device)   # 데이터 device로 올리기     \n",
    "        inputs = data['input'].to(device)\n",
    "        output = net(inputs) \n",
    "        loss = fn_loss(output,label)  # output과 label 사이의 loss 계산\n",
    "        # save loss\n",
    "        test_losses += [loss.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net,'../../model/seg/UNet.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
